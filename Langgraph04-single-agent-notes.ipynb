{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph 2.1: Single Agent Development\n",
    "\n",
    "## Complete Guide with Executable Examples\n",
    "\n",
    "### Topics Covered:\n",
    "1. **ReAct Pattern** (Reasoning and Acting)\n",
    "2. **Agent Nodes and Tool Integration**\n",
    "3. **Function Calling and Tool Execution**\n",
    "4. **Error Handling and Retries**\n",
    "5. **Basic Debugging Techniques**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install langgraph langchain-anthropic langchain-core -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from typing import Annotated, Literal, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Set your API key\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… Imports completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. ReAct Pattern - Reasoning and Acting\n",
    "\n",
    "## What is ReAct?\n",
    "\n",
    "ReAct is a paradigm where an agent alternates between:\n",
    "- **Reasoning**: Thinking about what to do next\n",
    "- **Acting**: Executing tools/actions based on reasoning\n",
    "- **Observing**: Processing the results of actions\n",
    "\n",
    "```\n",
    "User Query â†’ Reasoning â†’ Action â†’ Observation â†’ Reasoning â†’ Action â†’ ... â†’ Answer\n",
    "```\n",
    "\n",
    "### Benefits:\n",
    "- More interpretable agent behavior\n",
    "- Better error recovery\n",
    "- Reduced hallucination through grounding in tool results\n",
    "- Natural chain-of-thought reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Define Simple Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tools defined: calculate, get_weather\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def calculate(operation: str, a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Perform basic mathematical operations.\n",
    "    \n",
    "    Args:\n",
    "        operation: The operation to perform (add, subtract, multiply, divide)\n",
    "        a: First number\n",
    "        b: Second number\n",
    "    \n",
    "    Returns:\n",
    "        Result of the operation\n",
    "    \"\"\"\n",
    "    operations = {\n",
    "        \"add\": lambda x, y: x + y,\n",
    "        \"subtract\": lambda x, y: x - y,\n",
    "        \"multiply\": lambda x, y: x * y,\n",
    "        \"divide\": lambda x, y: x / y if y != 0 else \"Error: Division by zero\"\n",
    "    }\n",
    "    \n",
    "    if operation not in operations:\n",
    "        return f\"Error: Unknown operation {operation}\"\n",
    "    \n",
    "    result = operations[operation](a, b)\n",
    "    print(f\"ðŸ”§ Tool executed: {operation}({a}, {b}) = {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Get weather information for a location.\n",
    "    \n",
    "    Args:\n",
    "        location: City name or location\n",
    "    \n",
    "    Returns:\n",
    "        Weather information\n",
    "    \"\"\"\n",
    "    # Simulated weather data\n",
    "    weather_data = {\n",
    "        \"san francisco\": \"Sunny, 68Â°F\",\n",
    "        \"new york\": \"Cloudy, 55Â°F\",\n",
    "        \"london\": \"Rainy, 52Â°F\",\n",
    "        \"tokyo\": \"Clear, 72Â°F\"\n",
    "    }\n",
    "    \n",
    "    location_lower = location.lower()\n",
    "    weather = weather_data.get(location_lower, f\"Weather data not available for {location}\")\n",
    "    print(f\"ðŸ”§ Tool executed: get_weather('{location}') = {weather}\")\n",
    "    return weather\n",
    "\n",
    "print(\"âœ… Tools defined: calculate, get_weather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Define Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AgentState defined\n"
     ]
    }
   ],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"State of the agent including conversation history\"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "print(\"âœ… AgentState defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… create_react_agent function defined\n"
     ]
    }
   ],
   "source": [
    "def create_react_agent():\n",
    "    \"\"\"Create a ReAct agent with reasoning and acting capabilities\"\"\"\n",
    "    \n",
    "    # Initialize the LLM with tools\n",
    "    tools = [calculate, get_weather]\n",
    "    llm = ChatAnthropic(model=\"claude-sonnet-4-20250514\", temperature=0)\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    \n",
    "    # Define the agent node (reasoning)\n",
    "    def agent_node(state: AgentState):\n",
    "        \"\"\"Agent decides what to do next based on the current state\"\"\"\n",
    "        print(\"\\nðŸ§  REASONING: Agent is thinking...\")\n",
    "        response = llm_with_tools.invoke(state[\"messages\"])\n",
    "        print(f\"   Agent decision: {'Use tool' if response.tool_calls else 'Respond directly'}\")\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    # Build the graph\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"agent\", agent_node)\n",
    "    workflow.add_node(\"tools\", ToolNode(tools))\n",
    "    \n",
    "    # Add edges\n",
    "    workflow.add_edge(START, \"agent\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        tools_condition,  # Automatically routes based on tool calls\n",
    "    )\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "    \n",
    "    # Compile the graph\n",
    "    memory = MemorySaver()\n",
    "    app = workflow.compile(checkpointer=memory)\n",
    "    \n",
    "    return app\n",
    "\n",
    "print(\"âœ… create_react_agent function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Test ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Query: What is 15 multiplied by 8, and what's the weather in Tokyo?\n",
      "================================================================================\n",
      "\n",
      "ðŸ§  REASONING: Agent is thinking...\n",
      "   Agent decision: Use tool\n",
      "ðŸ”§ Tool executed: multiply(15.0, 8.0) = 120.0\n",
      "ðŸ”§ Tool executed: get_weather('Tokyo') = Clear, 72Â°F\n",
      "\n",
      "ðŸ§  REASONING: Agent is thinking...\n",
      "   Agent decision: Respond directly\n",
      "\n",
      "================================================================================\n",
      "âœ… Final Answer: Here are your answers:\n",
      "\n",
      "1. **15 multiplied by 8 = 120**\n",
      "\n",
      "2. **Weather in Tokyo: Clear, 72Â°F**\n",
      "\n",
      "The weather in Tokyo is currently clear with a temperature of 72Â°F (about 22Â°C).\n"
     ]
    }
   ],
   "source": [
    "# Create the agent\n",
    "react_agent = create_react_agent()\n",
    "\n",
    "# Test query requiring reasoning and acting\n",
    "query = \"What is 15 multiplied by 8, and what's the weather in Tokyo?\"\n",
    "\n",
    "print(f\"ðŸ“ Query: {query}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result = react_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=query)]},\n",
    "    config={\"configurable\": {\"thread_id\": \"react_example_1\"}}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"âœ… Final Answer: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Agent Nodes and Tool Integration\n",
    "\n",
    "## Advanced tool integration with custom node logic\n",
    "\n",
    "Let's create more sophisticated tools and track agent behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Define Advanced Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Advanced tools defined\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def search_database(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search a database for information.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "    \n",
    "    Returns:\n",
    "        Search results\n",
    "    \"\"\"\n",
    "    # Simulated database\n",
    "    database = {\n",
    "        \"python\": \"Python is a high-level programming language.\",\n",
    "        \"langgraph\": \"LangGraph is a library for building stateful agents.\",\n",
    "        \"react\": \"ReAct is a pattern for reasoning and acting.\"\n",
    "    }\n",
    "    \n",
    "    result = database.get(query.lower(), f\"No results found for '{query}'\")\n",
    "    print(f\"ðŸ”§ Tool: search_database('{query}') â†’ {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "@tool\n",
    "def save_to_file(filename: str, content: str) -> str:\n",
    "    \"\"\"\n",
    "    Save content to a file.\n",
    "    \n",
    "    Args:\n",
    "        filename: Name of the file\n",
    "        content: Content to save\n",
    "    \n",
    "    Returns:\n",
    "        Success message\n",
    "    \"\"\"\n",
    "    # Simulated file save\n",
    "    print(f\"ðŸ”§ Tool: save_to_file('{filename}', content_length={len(content)})\")\n",
    "    return f\"Successfully saved {len(content)} characters to {filename}\"\n",
    "\n",
    "print(\"âœ… Advanced tools defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Enhanced Agent State with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… EnhancedAgentState defined\n"
     ]
    }
   ],
   "source": [
    "class EnhancedAgentState(TypedDict):\n",
    "    \"\"\"Enhanced state with metadata\"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "    iteration_count: int\n",
    "    tool_calls_made: list\n",
    "\n",
    "print(\"âœ… EnhancedAgentState defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Create Enhanced Agent with Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… create_enhanced_agent function defined\n"
     ]
    }
   ],
   "source": [
    "def create_enhanced_agent():\n",
    "    \"\"\"Create an agent with custom node logic and multiple tools\"\"\"\n",
    "    \n",
    "    tools = [calculate, get_weather, search_database, save_to_file]\n",
    "    llm = ChatAnthropic(model=\"claude-sonnet-4-20250514\", temperature=0)\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    \n",
    "    # Custom agent node with metadata tracking\n",
    "    def custom_agent_node(state: EnhancedAgentState):\n",
    "        \"\"\"Agent with enhanced tracking\"\"\"\n",
    "        print(f\"\\nðŸ§  Agent Iteration #{state.get('iteration_count', 0) + 1}\")\n",
    "        \n",
    "        # Add system message for better reasoning\n",
    "        messages = state[\"messages\"]\n",
    "        if not any(isinstance(m, SystemMessage) for m in messages):\n",
    "            messages = [\n",
    "                SystemMessage(content=\"You are a helpful assistant. Think step-by-step.\")\n",
    "            ] + messages\n",
    "        \n",
    "        response = llm_with_tools.invoke(messages)\n",
    "        \n",
    "        # Track tool calls\n",
    "        tool_calls_made = state.get(\"tool_calls_made\", [])\n",
    "        if response.tool_calls:\n",
    "            for tc in response.tool_calls:\n",
    "                tool_calls_made.append(tc[\"name\"])\n",
    "        \n",
    "        return {\n",
    "            \"messages\": [response],\n",
    "            \"iteration_count\": state.get(\"iteration_count\", 0) + 1,\n",
    "            \"tool_calls_made\": tool_calls_made\n",
    "        }\n",
    "    \n",
    "    # Build graph\n",
    "    workflow = StateGraph(EnhancedAgentState)\n",
    "    workflow.add_node(\"agent\", custom_agent_node)\n",
    "    workflow.add_node(\"tools\", ToolNode(tools))\n",
    "    \n",
    "    workflow.add_edge(START, \"agent\")\n",
    "    workflow.add_conditional_edges(\"agent\", tools_condition)\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "    \n",
    "    return workflow.compile(checkpointer=MemorySaver())\n",
    "\n",
    "print(\"âœ… create_enhanced_agent function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Test Enhanced Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Query: Search for 'langgraph', then calculate 25 plus 17\n",
      "================================================================================\n",
      "\n",
      "ðŸ§  Agent Iteration #1\n",
      "ðŸ”§ Tool: search_database('langgraph') â†’ LangGraph is a library for building stateful agents.\n",
      "ðŸ”§ Tool executed: add(25.0, 17.0) = 42.0\n",
      "\n",
      "ðŸ§  Agent Iteration #2\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š Metadata:\n",
      "   Iterations: 2\n",
      "   Tools used: ['search_database', 'calculate']\n",
      "\n",
      "âœ… Final Answer: Here are the results:\n",
      "\n",
      "**Search results for 'langgraph':**\n",
      "LangGraph is a library for building stateful agents.\n",
      "\n",
      "**Calculation:**\n",
      "25 + 17 = 42\n"
     ]
    }
   ],
   "source": [
    "enhanced_agent = create_enhanced_agent()\n",
    "\n",
    "query = \"Search for 'langgraph', then calculate 25 plus 17\"\n",
    "\n",
    "print(f\"ðŸ“ Query: {query}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result = enhanced_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=query)], \"iteration_count\": 0, \"tool_calls_made\": []},\n",
    "    config={\"configurable\": {\"thread_id\": \"enhanced_1\"}}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"ðŸ“Š Metadata:\")\n",
    "print(f\"   Iterations: {result['iteration_count']}\")\n",
    "print(f\"   Tools used: {result['tool_calls_made']}\")\n",
    "print(f\"\\nâœ… Final Answer: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Function Calling and Tool Execution\n",
    "\n",
    "## Understanding how tools are called and executed\n",
    "\n",
    "Let's explore complex tool parameters and custom execution logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Tool with Complex Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… create_report tool defined\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def create_report(\n",
    "    title: str,\n",
    "    sections: list[str],\n",
    "    include_summary: bool = True\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Create a structured report.\n",
    "    \n",
    "    Args:\n",
    "        title: Report title\n",
    "        sections: List of section names\n",
    "        include_summary: Whether to include a summary\n",
    "    \n",
    "    Returns:\n",
    "        Formatted report\n",
    "    \"\"\"\n",
    "    report = f\"# {title}\\n\\n\"\n",
    "    \n",
    "    for i, section in enumerate(sections, 1):\n",
    "        report += f\"## {i}. {section}\\n[Content for {section}]\\n\\n\"\n",
    "    \n",
    "    if include_summary:\n",
    "        report += \"## Summary\\n[Report summary]\\n\"\n",
    "    \n",
    "    print(f\"ðŸ”§ Tool: create_report(title='{title}', sections={len(sections)})\")\n",
    "    return report\n",
    "\n",
    "print(\"âœ… create_report tool defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Custom Tool Executor with Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ToolExecutor class defined\n"
     ]
    }
   ],
   "source": [
    "class ToolExecutor:\n",
    "    \"\"\"Custom tool executor with detailed logging\"\"\"\n",
    "    \n",
    "    def __init__(self, tools):\n",
    "        self.tools = {tool.name: tool for tool in tools}\n",
    "        self.execution_log = []\n",
    "    \n",
    "    def execute(self, tool_name: str, tool_input: dict):\n",
    "        \"\"\"Execute a tool and log the execution\"\"\"\n",
    "        print(f\"\\nâš™ï¸  Executing: {tool_name}\")\n",
    "        print(f\"   Input: {tool_input}\")\n",
    "        \n",
    "        if tool_name not in self.tools:\n",
    "            error = f\"Tool '{tool_name}' not found\"\n",
    "            print(f\"   âŒ Error: {error}\")\n",
    "            return {\"error\": error}\n",
    "        \n",
    "        try:\n",
    "            tool = self.tools[tool_name]\n",
    "            result = tool.invoke(tool_input)\n",
    "            \n",
    "            self.execution_log.append({\n",
    "                \"tool\": tool_name,\n",
    "                \"input\": tool_input,\n",
    "                \"output\": result,\n",
    "                \"status\": \"success\"\n",
    "            })\n",
    "            \n",
    "            print(f\"   âœ… Success\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"   âŒ Error: {error_msg}\")\n",
    "            \n",
    "            self.execution_log.append({\n",
    "                \"tool\": tool_name,\n",
    "                \"input\": tool_input,\n",
    "                \"error\": error_msg,\n",
    "                \"status\": \"failed\"\n",
    "            })\n",
    "            \n",
    "            return {\"error\": error_msg}\n",
    "    \n",
    "    def get_log(self):\n",
    "        \"\"\"Get execution log\"\"\"\n",
    "        return self.execution_log\n",
    "\n",
    "print(\"âœ… ToolExecutor class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Test Tool Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Testing Tool Executor\n",
      "================================================================================\n",
      "\n",
      "âš™ï¸  Executing: calculate\n",
      "   Input: {'operation': 'multiply', 'a': 12, 'b': 5}\n",
      "ðŸ”§ Tool executed: multiply(12.0, 5.0) = 60.0\n",
      "   âœ… Success\n",
      "\n",
      "âš™ï¸  Executing: create_report\n",
      "   Input: {'title': 'Q4 Report', 'sections': ['Introduction', 'Results', 'Conclusion'], 'include_summary': True}\n",
      "ðŸ”§ Tool: create_report(title='Q4 Report', sections=3)\n",
      "   âœ… Success\n",
      "\n",
      "âš™ï¸  Executing: nonexistent_tool\n",
      "   Input: {}\n",
      "   âŒ Error: Tool 'nonexistent_tool' not found\n",
      "\n",
      "================================================================================\n",
      "ðŸ“‹ Execution Log:\n",
      "\n",
      "   1. calculate: success\n",
      "\n",
      "   2. create_report: success\n"
     ]
    }
   ],
   "source": [
    "executor = ToolExecutor([calculate, create_report])\n",
    "\n",
    "print(\"ðŸ“ Testing Tool Executor\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Execute tools\n",
    "executor.execute(\"calculate\", {\"operation\": \"multiply\", \"a\": 12, \"b\": 5})\n",
    "executor.execute(\"create_report\", {\n",
    "    \"title\": \"Q4 Report\",\n",
    "    \"sections\": [\"Introduction\", \"Results\", \"Conclusion\"],\n",
    "    \"include_summary\": True\n",
    "})\n",
    "executor.execute(\"nonexistent_tool\", {})  # Error case\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ðŸ“‹ Execution Log:\")\n",
    "for i, log_entry in enumerate(executor.get_log(), 1):\n",
    "    print(f\"\\n   {i}. {log_entry['tool']}: {log_entry['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Error Handling and Retries\n",
    "\n",
    "## Building robust agents that can handle failures\n",
    "\n",
    "Real-world applications need to handle:\n",
    "- Network failures\n",
    "- API timeouts\n",
    "- Invalid inputs\n",
    "- Tool errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Simulated Unreliable Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… unreliable_api tool defined\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "@tool\n",
    "def unreliable_api(data: str, fail_probability: float = 0.5) -> str:\n",
    "    \"\"\"\n",
    "    Simulates an unreliable API that might fail.\n",
    "    \n",
    "    Args:\n",
    "        data: Data to process\n",
    "        fail_probability: Probability of failure (0-1)\n",
    "    \n",
    "    Returns:\n",
    "        Processed data or error\n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    if random.random() < fail_probability:\n",
    "        raise Exception(\"API temporarily unavailable\")\n",
    "    \n",
    "    return f\"Processed: {data}\"\n",
    "\n",
    "print(\"âœ… unreliable_api tool defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Agent State with Retry Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RetryableAgentState defined\n"
     ]
    }
   ],
   "source": [
    "class RetryableAgentState(TypedDict):\n",
    "    \"\"\"State with retry tracking\"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "    retry_count: int\n",
    "    max_retries: int\n",
    "    last_error: str | None\n",
    "\n",
    "print(\"âœ… RetryableAgentState defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Create Agent with Retry Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… create_agent_with_retry function defined\n"
     ]
    }
   ],
   "source": [
    "def create_agent_with_retry():\n",
    "    \"\"\"Create an agent with built-in retry logic\"\"\"\n",
    "    \n",
    "    tools = [calculate, unreliable_api]\n",
    "    llm = ChatAnthropic(model=\"claude-sonnet-4-20250514\", temperature=0)\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    \n",
    "    def agent_with_error_handling(state: RetryableAgentState):\n",
    "        \"\"\"Agent node with error awareness\"\"\"\n",
    "        print(f\"\\nðŸ§  Agent (Retry count: {state.get('retry_count', 0)})\")\n",
    "        \n",
    "        messages = state[\"messages\"]\n",
    "        \n",
    "        # If there was an error, inform the agent\n",
    "        if state.get(\"last_error\"):\n",
    "            error_msg = f\"Previous action failed with error: {state['last_error']}. Try a different approach.\"\n",
    "            messages = messages + [SystemMessage(content=error_msg)]\n",
    "            print(f\"   âš ï¸  Informing agent of error: {state['last_error']}\")\n",
    "        \n",
    "        response = llm_with_tools.invoke(messages)\n",
    "        \n",
    "        return {\n",
    "            \"messages\": [response],\n",
    "            \"last_error\": None  # Clear error after processing\n",
    "        }\n",
    "    \n",
    "    def tools_with_retry(state: RetryableAgentState):\n",
    "        \"\"\"Tool execution with retry logic\"\"\"\n",
    "        max_retries = state.get(\"max_retries\", 3)\n",
    "        retry_count = state.get(\"retry_count\", 0)\n",
    "        \n",
    "        last_message = state[\"messages\"][-1]\n",
    "        \n",
    "        for tool_call in last_message.tool_calls:\n",
    "            attempt = 0\n",
    "            while attempt < max_retries:\n",
    "                try:\n",
    "                    print(f\"\\nâš™ï¸  Executing {tool_call['name']} (attempt {attempt + 1}/{max_retries})\")\n",
    "                    \n",
    "                    # Execute tool\n",
    "                    tool = next(t for t in tools if t.name == tool_call[\"name\"])\n",
    "                    result = tool.invoke(tool_call[\"args\"])\n",
    "                    \n",
    "                    print(f\"   âœ… Success!\")\n",
    "                    \n",
    "                    # Create tool message\n",
    "                    return {\n",
    "                        \"messages\": [ToolMessage(\n",
    "                            content=str(result),\n",
    "                            tool_call_id=tool_call[\"id\"]\n",
    "                        )],\n",
    "                        \"retry_count\": 0,  # Reset on success\n",
    "                        \"last_error\": None\n",
    "                    }\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    attempt += 1\n",
    "                    error_msg = str(e)\n",
    "                    print(f\"   âŒ Failed: {error_msg}\")\n",
    "                    \n",
    "                    if attempt < max_retries:\n",
    "                        print(f\"   ðŸ”„ Retrying in 1 second...\")\n",
    "                        sleep(1)\n",
    "                    else:\n",
    "                        print(f\"   âŒ Max retries reached\")\n",
    "                        return {\n",
    "                            \"messages\": [ToolMessage(\n",
    "                                content=f\"Error after {max_retries} attempts: {error_msg}\",\n",
    "                                tool_call_id=tool_call[\"id\"]\n",
    "                            )],\n",
    "                            \"retry_count\": retry_count + 1,\n",
    "                            \"last_error\": error_msg\n",
    "                        }\n",
    "        \n",
    "        return {\"retry_count\": 0, \"last_error\": None}\n",
    "    \n",
    "    # Build graph\n",
    "    workflow = StateGraph(RetryableAgentState)\n",
    "    workflow.add_node(\"agent\", agent_with_error_handling)\n",
    "    workflow.add_node(\"tools\", tools_with_retry)\n",
    "    \n",
    "    workflow.add_edge(START, \"agent\")\n",
    "    workflow.add_conditional_edges(\"agent\", tools_condition)\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "    \n",
    "    return workflow.compile(checkpointer=MemorySaver())\n",
    "\n",
    "print(\"âœ… create_agent_with_retry function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Test Retry Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Testing Error Handling with Retries\n",
      "================================================================================\n",
      "\n",
      "ðŸ§  Agent (Retry count: 0)\n",
      "\n",
      "âš™ï¸  Executing calculate (attempt 1/3)\n",
      "ðŸ”§ Tool executed: add(10.0, 5.0) = 15.0\n",
      "   âœ… Success!\n",
      "\n",
      "ðŸ§  Agent (Retry count: 0)\n",
      "\n",
      "================================================================================\n",
      "âœ… Final result received\n"
     ]
    }
   ],
   "source": [
    "retry_agent = create_agent_with_retry()\n",
    "\n",
    "print(\"ðŸ“ Testing Error Handling with Retries\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# This might fail and retry\n",
    "result = retry_agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Calculate 10 + 5\")],\n",
    "        \"retry_count\": 0,\n",
    "        \"max_retries\": 3,\n",
    "        \"last_error\": None\n",
    "    },\n",
    "    config={\"configurable\": {\"thread_id\": \"retry_1\"}}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"âœ… Final result received\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Basic Debugging Techniques\n",
    "\n",
    "## Monitoring and debugging agent behavior\n",
    "\n",
    "Effective debugging is crucial for:\n",
    "- Understanding agent decisions\n",
    "- Identifying bottlenecks\n",
    "- Catching errors early\n",
    "- Optimizing performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Debug Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DebugAgentState defined\n"
     ]
    }
   ],
   "source": [
    "class DebugAgentState(TypedDict):\n",
    "    \"\"\"State with debug information\"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "    debug_log: list\n",
    "\n",
    "print(\"âœ… DebugAgentState defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Create Debuggable Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… create_debuggable_agent function defined\n"
     ]
    }
   ],
   "source": [
    "def create_debuggable_agent():\n",
    "    \"\"\"Create an agent with comprehensive debugging\"\"\"\n",
    "    \n",
    "    tools = [calculate, get_weather]\n",
    "    llm = ChatAnthropic(model=\"claude-sonnet-4-20250514\", temperature=0)\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    \n",
    "    def debug_agent_node(state: DebugAgentState):\n",
    "        \"\"\"Agent node with debug logging\"\"\"\n",
    "        debug_log = state.get(\"debug_log\", [])\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"ðŸ› DEBUG: Agent Node Execution\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Log current state\n",
    "        print(f\"Messages in state: {len(state['messages'])}\")\n",
    "        print(f\"Last message: {state['messages'][-1].content[:100]}...\")\n",
    "        \n",
    "        debug_log.append({\n",
    "            \"node\": \"agent\",\n",
    "            \"message_count\": len(state['messages']),\n",
    "            \"last_message_type\": type(state['messages'][-1]).__name__\n",
    "        })\n",
    "        \n",
    "        # Invoke LLM\n",
    "        print(\"\\nðŸ“ž Calling LLM...\")\n",
    "        response = llm_with_tools.invoke(state[\"messages\"])\n",
    "        \n",
    "        print(f\"âœ… LLM Response received\")\n",
    "        print(f\"   Tool calls: {len(response.tool_calls) if response.tool_calls else 0}\")\n",
    "        print(f\"   Content length: {len(response.content) if response.content else 0}\")\n",
    "        \n",
    "        if response.tool_calls:\n",
    "            print(\"\\nðŸ”§ Tool Calls Requested:\")\n",
    "            for tc in response.tool_calls:\n",
    "                print(f\"   - {tc['name']}({tc['args']})\")\n",
    "        \n",
    "        debug_log.append({\n",
    "            \"node\": \"agent\",\n",
    "            \"tool_calls\": len(response.tool_calls) if response.tool_calls else 0,\n",
    "            \"response_type\": \"tool_call\" if response.tool_calls else \"text\"\n",
    "        })\n",
    "        \n",
    "        return {\"messages\": [response], \"debug_log\": debug_log}\n",
    "    \n",
    "    def debug_tool_node(state: DebugAgentState):\n",
    "        \"\"\"Tool node with debug logging\"\"\"\n",
    "        debug_log = state.get(\"debug_log\", [])\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"ðŸ› DEBUG: Tool Node Execution\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        last_message = state[\"messages\"][-1]\n",
    "        \n",
    "        print(f\"Tool calls to execute: {len(last_message.tool_calls)}\")\n",
    "        \n",
    "        # Execute tools\n",
    "        tool_node = ToolNode(tools)\n",
    "        result = tool_node.invoke(state)\n",
    "        \n",
    "        print(f\"âœ… Tools executed: {len(result['messages'])} results\")\n",
    "        \n",
    "        for i, msg in enumerate(result[\"messages\"], 1):\n",
    "            print(f\"   {i}. {msg.content[:100]}...\")\n",
    "        \n",
    "        debug_log.append({\n",
    "            \"node\": \"tools\",\n",
    "            \"tools_executed\": len(result[\"messages\"]),\n",
    "            \"results\": [str(m.content)[:50] for m in result[\"messages\"]]\n",
    "        })\n",
    "        \n",
    "        result[\"debug_log\"] = debug_log\n",
    "        return result\n",
    "    \n",
    "    # Build graph\n",
    "    workflow = StateGraph(DebugAgentState)\n",
    "    workflow.add_node(\"agent\", debug_agent_node)\n",
    "    workflow.add_node(\"tools\", debug_tool_node)\n",
    "    \n",
    "    workflow.add_edge(START, \"agent\")\n",
    "    workflow.add_conditional_edges(\"agent\", tools_condition)\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "    \n",
    "    return workflow.compile(checkpointer=MemorySaver())\n",
    "\n",
    "print(\"âœ… create_debuggable_agent function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Test Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Testing Agent with Debug Logging\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "ðŸ› DEBUG: Agent Node Execution\n",
      "============================================================\n",
      "Messages in state: 1\n",
      "Last message: What is 100 divided by 4, and what's the weather in London?...\n",
      "\n",
      "ðŸ“ž Calling LLM...\n",
      "âœ… LLM Response received\n",
      "   Tool calls: 2\n",
      "   Content length: 3\n",
      "\n",
      "ðŸ”§ Tool Calls Requested:\n",
      "   - calculate({'operation': 'divide', 'a': 100, 'b': 4})\n",
      "   - get_weather({'location': 'London'})\n",
      "\n",
      "============================================================\n",
      "ðŸ› DEBUG: Tool Node Execution\n",
      "============================================================\n",
      "Tool calls to execute: 2\n",
      "ðŸ”§ Tool executed: divide(100.0, 4.0) = 25.0\n",
      "ðŸ”§ Tool executed: get_weather('London') = Rainy, 52Â°F\n",
      "âœ… Tools executed: 2 results\n",
      "   1. 25.0...\n",
      "   2. Rainy, 52Â°F...\n",
      "\n",
      "============================================================\n",
      "ðŸ› DEBUG: Agent Node Execution\n",
      "============================================================\n",
      "Messages in state: 4\n",
      "Last message: Rainy, 52Â°F...\n",
      "\n",
      "ðŸ“ž Calling LLM...\n",
      "âœ… LLM Response received\n",
      "   Tool calls: 0\n",
      "   Content length: 141\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š DEBUG LOG SUMMARY\n",
      "================================================================================\n",
      "\n",
      "1. Node: agent\n",
      "   message_count: 1\n",
      "   last_message_type: HumanMessage\n",
      "\n",
      "2. Node: agent\n",
      "   tool_calls: 2\n",
      "   response_type: tool_call\n",
      "\n",
      "3. Node: tools\n",
      "   tools_executed: 2\n",
      "   results: ['25.0', 'Rainy, 52Â°F']\n",
      "\n",
      "4. Node: agent\n",
      "   message_count: 4\n",
      "   last_message_type: ToolMessage\n",
      "\n",
      "5. Node: agent\n",
      "   tool_calls: 0\n",
      "   response_type: text\n"
     ]
    }
   ],
   "source": [
    "debug_agent = create_debuggable_agent()\n",
    "\n",
    "print(\"ðŸ“ Testing Agent with Debug Logging\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result = debug_agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"What is 100 divided by 4, and what's the weather in London?\")],\n",
    "        \"debug_log\": []\n",
    "    },\n",
    "    config={\"configurable\": {\"thread_id\": \"debug_1\"}}\n",
    ")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"ðŸ“Š DEBUG LOG SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, entry in enumerate(result[\"debug_log\"], 1):\n",
    "    print(f\"\\n{i}. Node: {entry['node']}\")\n",
    "    for key, value in entry.items():\n",
    "        if key != 'node':\n",
    "            print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Bonus: Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Agent Graph Structure:\n",
      "------------------------------------------------------------\n",
      "        +-----------+         \n",
      "        | __start__ |         \n",
      "        +-----------+         \n",
      "               *              \n",
      "               *              \n",
      "               *              \n",
      "          +-------+           \n",
      "          | agent |           \n",
      "          +-------+.          \n",
      "          .         .         \n",
      "        ..           ..       \n",
      "       .               .      \n",
      "+---------+         +-------+ \n",
      "| __end__ |         | tools | \n",
      "+---------+         +-------+ \n"
     ]
    }
   ],
   "source": [
    "def visualize_graph_structure(agent):\n",
    "    \"\"\"Display the structure of an agent graph\"\"\"\n",
    "    print(\"\\nðŸ“Š Agent Graph Structure:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Get graph representation\n",
    "    try:\n",
    "        graph_ascii = agent.get_graph().draw_ascii()\n",
    "        print(graph_ascii)\n",
    "    except Exception as e:\n",
    "        print(f\"ASCII visualization not available: {e}\")\n",
    "        print(\"\\nGraph components:\")\n",
    "        print(f\"  Nodes: {list(agent.get_graph().nodes.keys())}\")\n",
    "        print(f\"  Edges: Present but structure not displayable in ASCII\")\n",
    "\n",
    "visualize_graph_structure(react_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary and Key Takeaways\n",
    "\n",
    "## 1. ReAct Pattern\n",
    "- Interleaves reasoning and acting\n",
    "- Agent thinks, uses tools, observes results\n",
    "- More reliable than pure prompting\n",
    "\n",
    "## 2. Agent Nodes\n",
    "- Custom logic for decision making\n",
    "- State management and tracking\n",
    "- Integration with multiple tools\n",
    "\n",
    "## 3. Tool Execution\n",
    "- Declarative tool definitions with `@tool` decorator\n",
    "- Automatic parameter validation\n",
    "- Structured inputs and outputs\n",
    "\n",
    "## 4. Error Handling\n",
    "- Retry logic for transient failures\n",
    "- Error propagation to agent\n",
    "- Graceful degradation\n",
    "\n",
    "## 5. Debugging\n",
    "- Comprehensive logging\n",
    "- State inspection\n",
    "- Execution tracing\n",
    "\n",
    "**Remember:** Always test agents with edge cases and monitor their behavior!\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Try modifying the tools with your own logic\n",
    "2. Experiment with different LLM models\n",
    "3. Build multi-agent systems\n",
    "4. Add persistence and memory\n",
    "5. Deploy to production with proper monitoring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
