{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06404e9-b467-4acb-aca3-20bdd1324d73",
   "metadata": {},
   "source": [
    "# Text as Data â€“ Tokenization & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09eae386-8a00-4239-b049-98018968da6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hello!!! This is my FIRST GenAI & NLP class... #excited\n",
      "Lower + cleaned: hello this is my first genai nlp class excited\n",
      "Tokens: ['hello', 'this', 'is', 'my', 'first', 'genai', 'nlp', 'class', 'excited']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello!!! This is my FIRST GenAI & NLP class... #excited\"\n",
    "\n",
    "import re\n",
    "\n",
    "# 1) Basic cleaning\n",
    "text_lower = text.lower()\n",
    "text_clean = re.sub(r\"[^a-z0-9\\s]\", \" \", text_lower)  # keep letters, digits, spaces\n",
    "text_clean = re.sub(r\"\\s+\", \" \", text_clean).strip()\n",
    "\n",
    "print(\"Original:\", text)\n",
    "print(\"Lower + cleaned:\", text_clean)\n",
    "\n",
    "# 2) Tokenization (simple split)\n",
    "tokens = text_clean.split()\n",
    "print(\"Tokens:\", tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534e4e7-f253-41f8-848c-81c8505ae04c",
   "metadata": {},
   "source": [
    "# Bag of Words & TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e230ec7-8a48-4e9c-b7be-072153270f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary (BoW): ['amazon' 'and' 'are' 'available' 'beautiful' 'ethnic' 'in' 'kurtis'\n",
      " 'offline' 'online' 'our' 'sarees' 'sell' 'sells' 'store' 'we' 'wear']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazon</th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>available</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>in</th>\n",
       "      <th>kurtis</th>\n",
       "      <th>offline</th>\n",
       "      <th>online</th>\n",
       "      <th>our</th>\n",
       "      <th>sarees</th>\n",
       "      <th>sell</th>\n",
       "      <th>sells</th>\n",
       "      <th>store</th>\n",
       "      <th>we</th>\n",
       "      <th>wear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazon  and  are  available  beautiful  ethnic  in  kurtis  offline  \\\n",
       "0       1    0    0          0          1       0   0       0        0   \n",
       "1       0    1    1          1          0       0   1       1        0   \n",
       "2       0    1    0          0          0       1   0       0        1   \n",
       "\n",
       "   online  our  sarees  sell  sells  store  we  wear  \n",
       "0       1    0       1     0      1      0   0     0  \n",
       "1       1    1       1     0      0      1   0     0  \n",
       "2       1    0       0     1      0      0   1     1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "docs = [\n",
    "    \"Amazon sells beautiful sarees online\",\n",
    "    \"Sarees and kurtis are available in our online store\",\n",
    "    \"We sell ethnic wear online and offline\"\n",
    "]\n",
    "\n",
    "# Bag of Words\n",
    "bow_vec = CountVectorizer()\n",
    "bow_matrix = bow_vec.fit_transform(docs)\n",
    "\n",
    "print(\"Vocabulary (BoW):\", bow_vec.get_feature_names_out())\n",
    "pd.DataFrame(bow_matrix.toarray(), columns=bow_vec.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17071a75-aa6c-4517-a4ac-96a8137f0e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary (TF-IDF): ['amazon' 'and' 'are' 'available' 'beautiful' 'ethnic' 'in' 'kurtis'\n",
      " 'offline' 'online' 'our' 'sarees' 'sell' 'sells' 'store' 'we' 'wear']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazon</th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>available</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>in</th>\n",
       "      <th>kurtis</th>\n",
       "      <th>offline</th>\n",
       "      <th>online</th>\n",
       "      <th>our</th>\n",
       "      <th>sarees</th>\n",
       "      <th>sell</th>\n",
       "      <th>sells</th>\n",
       "      <th>store</th>\n",
       "      <th>we</th>\n",
       "      <th>wear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.529</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazon    and    are  available  beautiful  ethnic     in  kurtis  offline  \\\n",
       "0   0.529  0.000  0.000      0.000      0.529    0.00  0.000   0.000     0.00   \n",
       "1   0.000  0.284  0.374      0.374      0.000    0.00  0.374   0.374     0.00   \n",
       "2   0.000  0.297  0.000      0.000      0.000    0.39  0.000   0.000     0.39   \n",
       "\n",
       "   online    our  sarees  sell  sells  store    we  wear  \n",
       "0    0.00  0.000   0.402  0.00  0.529  0.000  0.00  0.00  \n",
       "1    0.00  0.374   0.284  0.00  0.000  0.374  0.00  0.00  \n",
       "2    0.39  0.000   0.000  0.39  0.000  0.000  0.39  0.39  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vec.fit_transform(docs)\n",
    "\n",
    "print(\"Vocabulary (TF-IDF):\", tfidf_vec.get_feature_names_out())\n",
    "pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vec.get_feature_names_out()).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d7ad5-7d1f-4135-be81-41c487e61078",
   "metadata": {},
   "source": [
    "# Word/Sentence Embeddings + Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4150e05f-4e31-419d-b1c2-20cea4d42c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LotusBlue\\anaconda3\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LotusBlue\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Similarity with: 'Amazon sells sarees and ethnic wear.' = 1.000\n",
      "Similarity with: 'We offer traditional sarees in our shop.' = 0.741\n",
      "Similarity with: 'I love eating pizza on weekends.' = -0.001\n"
     ]
    }
   ],
   "source": [
    "# !pip install sentence-transformers   # if not already installed\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # small, fast model\n",
    "\n",
    "sentences = [\n",
    "    \"Amazon sells sarees and ethnic wear.\",\n",
    "    \"We offer traditional sarees in our shop.\",\n",
    "    \"I love eating pizza on weekends.\"\n",
    "]\n",
    "\n",
    "embs = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "# Similarity between sentence 0 and others\n",
    "cos_sim = util.cos_sim(embs[0], embs)\n",
    "\n",
    "for i, s in enumerate(sentences):\n",
    "    print(f\"Similarity with: {s!r} = {cos_sim[0][i].item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5806f19-8965-4ea9-a52e-a8b7a4e70421",
   "metadata": {},
   "source": [
    "# Simple Text Classification (Sentiment-ish) with TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e15d0f75-e8bf-4288-8f0e-acaacc60722f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test texts: ['I love this product', 'This saree is amazing']\n",
      "Predictions: [0 0]\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "texts = [\n",
    "    \"I love this product\",        # 1\n",
    "    \"This saree is amazing\",      # 1\n",
    "    \"Worst experience ever\",      # 0\n",
    "    \"I hate this quality\",        # 0\n",
    "    \"Very good material\",         # 1\n",
    "    \"Terrible service\",           # 0\n",
    "]\n",
    "labels = [1, 1, 0, 0, 1, 0]   # 1 = positive, 0 = negative\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "X_train_vec = vec.fit_transform(X_train)\n",
    "X_test_vec  = vec.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "print(\"Test texts:\", X_test)\n",
    "print(\"Predictions:\", y_pred)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd75494-cf34-40ec-a880-db050f0796a3",
   "metadata": {},
   "source": [
    "# NER and POS Tagging with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3d6de75-8634-4855-8644-bcb325be8270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 6.7 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.6/12.8 MB 6.6 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 3.9/12.8 MB 6.5 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 6.8 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 7.2 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.9/12.8 MB 7.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 7.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 7.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 7.6 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7808f577-7eeb-4372-b30a-0190f2e88f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tokens & POS ===\n",
      "Keerthi -> PROPN\n",
      "visited -> VERB\n",
      "Dubai -> PROPN\n",
      "last -> ADJ\n",
      "week -> NOUN\n",
      "and -> CCONJ\n",
      "bought -> VERB\n",
      "sarees -> NOUN\n",
      "from -> ADP\n",
      "branded -> ADJ\n",
      "shop -> NOUN\n",
      ". -> PUNCT\n",
      "\n",
      "=== Named Entities ===\n",
      "Keerthi -> ORG\n",
      "Dubai -> GPE\n",
      "last week -> DATE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Keerthi visited Dubai last week and bought sarees from branded shop.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "print(\"=== Tokens & POS ===\")\n",
    "for token in doc:\n",
    "    print(token.text, \"->\", token.pos_)\n",
    "\n",
    "print(\"\\n=== Named Entities ===\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \"->\", ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3837e503-ec58-4089-b31c-7543609d98cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89c4f8-5c7f-4ebe-aaf2-02b125ce5da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920fb400-fc16-4816-beff-db4af4aa7ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
