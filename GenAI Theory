Generative AI refers to a class of artificial intelligence systems that can create new content—such as text, images, audio, video, or even code—based on patterns learned from existing data. Unlike traditional AI, which focuses on analyzing or predicting, generative AI is about producing original outputs that resemble human-created content.
Key Characteristics

Uses machine learning models (often deep learning) to learn patterns from large datasets.
Generates new data rather than just classifying or predicting.
Often powered by transformer-based architectures like GPT (for text) or diffusion models (for images).

Examples

Text generation: Chatbots, content creation tools (e.g., GPT models).
Image generation: Tools like DALL·E or Midjourney.
Audio & music: AI that composes songs or generates voices.
Code generation: AI that writes or optimizes programming code.

Types of Generative Models 
LLM
Vision Models
Audio and Speech models
Multi models
Agentic AI systems

How It Works
Generative AI models typically use techniques like:

Java developers : Code generations, Code refactoring, API development using GenAI, GenAI in springboot application, AI based unit test generation. 
ETL developers: Data cleaning automation, Intelligent data classification, PII detection, Query generation(SQL/Big Query/Sqnoflake), Metadata enrichment, Automated documentation.

Generative Adversarial Networks (GANs): Two neural networks (generator and discriminator) compete to create realistic outputs.
Variational Autoencoders (VAEs): Encode and decode data to generate variations.
Transformers: Predict next tokens in sequences, enabling coherent text or structured outputs.

Evolution from ML → DL → Transformers → GenAI

ML Era: Algorithms like decision trees, SVMs, and regression dominated. Focus was on prediction and classification.
DL Era: Neural networks became deeper (CNNs for vision, RNNs for sequences). Enabled breakthroughs in speech and image recognition.
Transformer Era (2017 onward): Introduced by Attention Is All You Need. Transformers revolutionized NLP by enabling large-scale language models (e.g., GPT, BERT).
Generative AI Era: Leveraging transformers and diffusion models for creative tasks—text generation (ChatGPT), image generation (DALL·E), video, and multimodal AI.

What are tokens?

Tokens are the basic units of text that a model processes. They can be words, subwords, or even characters depending on the tokenizer.
Example:

Sentence: “Generative AI is amazing.”
Tokens: ["Gener", "ative", " AI", " is", " amazing", "."] (subword tokens)





Why tokens matter?

Models don’t understand raw text; they understand numerical representations of tokens.
Tokenization breaks text into manageable pieces for the model.



Token Limit

Every model has a context window (e.g., GPT-4 has ~128k tokens). This limits how much text it can process at once.


What Are Embeddings? 
Embeddings are numerical representations of text (or images, audio, code) that capture their meaning.
Embeddings turn words/sentences/documents into numbers so that a machine can understand similarity and meaning.

Why Do We Need Embeddings?
Computers cannot understand text directly.
They understand vectors (lists of numbers).

Input	Output
"apple"	[0.12, -0.98, 0.45, ...]

Words/sentences with similar meaning will have vectors that are close to each other in space.
"king" is close to "queen"


How they are used in GenAI?
Input tokens >>> converted to embeddings >>> processed by transformer layers >>> output embeddings >>> decoded back into text.


What Is Attention in GenAI?
Attention is a mechanism in transformer models that lets the model decide which words to focus on when understanding or generating text.

Workflow in GenAI

Text Input >>> Tokenization >>> Tokens
Tokens >>> Embeddings (vectors)
Transformer layers process embeddings using attention
Generate new embeddings >>> Convert back to tokens >>> Output text


Temperature
============
Controls randomness in output.

0.0 – 0.3 → deterministic, precise, factual
0.5 – 0.7 → balanced, natural language
0.8 – 1.2 → creative, more varied
>1.2 → chaotic (rarely used)

Use cases:
==========
0.1 → RAG, finance, medical, code generation
0.7 → general conversation
1.1 → story writing, brainstorming

Top-k Sampling
==============
Limits choices to top-k most likely tokens.

k = 1 → fully deterministic
k = 10 → safe + controlled creativity
k = 100 → very creative
k > 200 → too random

Idea: Model picks the next token only from the top-k most probable words.


Top-p (Nucleus Sampling)

Choose tokens whose cumulative probability ≤ p.

p = 0.1 → highly focused
p = 0.5 → balanced
p = 0.9 → creative
p = 1.0 → full distribution

Top-p is smoother than top-k and often preferred.


Suppose the model predicts the next word with these probabilities:

Word	Probability
eat	0.40
go	0.30
read	0.15
walk	0.10
car	0.05

Now let’s see different top-p settings:
We pick only the most probable words until their total probability ≥ 0.5:

eat = 0.40
go = 0.30 → now total = 0.70 (≥0.5)
So the model only chooses between “eat” and “go.”


What is Prompting in GenAI?
Prompting is the process of giving instructions to a Generative AI model (like ChatGPT, GPT-5, Claude, Gemini) so it produces the output you want.
Prompting is the art and technique of giving precise instructions to a GenAI model so it produces the desired output

WHY IS PROMPTING IMPORTANT?
LLMs do not understand things like humans. They follow patterns based on:
how the prompt is written
what details it includes
what constraints it gives

Good prompting =
+ more accurate answers
+ less hallucination
+ better reasoning
+ more control
+ better code
+ better summaries

Bad prompt:
“Explain Python.”

Good prompt:
“Explain Python to a beginner in 5 bullet points with simple examples.”

TYPES OF PROMPTS (Simple Overview)
1. Zero-shot prompting
No examples, just instructions.
Example: “Summarize this.”

2. One-shot prompting
One example included.

3. Few-shot prompting
Multiple examples included.

4. Chain-of-thought prompting
Ask the model to “think step-by-step”.

5. Role prompting
Assign a persona:
“You are a senior Python expert…”

6. Structured prompting
Force JSON, tables, specific formats.

7. System + User prompting
Used in APIs:
+ System = rules
+ User = request
