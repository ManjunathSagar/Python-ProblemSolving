{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f98cd5bb-3de9-4001-9bab-237136c8f03e",
   "metadata": {},
   "source": [
    "### What is an Embedding?\n",
    "\n",
    "An embedding is a way to convert text into numbers (vectors) so that a machine can understand meaning.\n",
    "\n",
    "Text  â†’  Embedding Model  â†’  Vector (numbers)\n",
    "\n",
    "\n",
    "1. Vectors: Embeddings are arrays of numbers. Each text â†’ one vector. Example: [0.23, -0.11, 0.78, ...]\n",
    "2. Dimension: Length of the vector. More dimensions â†’ better meaning capture (usually). Examples: 384 dimensions, 768 dimensions\n",
    "3. Semantic Similarity: Similar meaning â†’ vectors closer together\n",
    "4. Distance / Similarity Measures: Used to compare vectors:\n",
    "    1. Cosine similarity (most common): Higher similarity score = closer meaning\n",
    "    2. Euclidean distance\n",
    "    3. Dot product\n",
    "\n",
    "\"Silk saree\"\t\"Banarasi saree\"\tVery similar\n",
    "\"Silk saree\"\t\"Laptop charger\"\tNot similar\n",
    "\n",
    "### OpenAI Embeddings\n",
    "What are OpenAI Embeddings?\n",
    "\n",
    "Pre-trained, high-quality embeddings provided by OpenAI.\n",
    "\n",
    "Popular model:\n",
    "\n",
    "+ text-embedding-3-small\n",
    "+ text-embedding-3-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b77e61-08fe-4072-8dc9-cd7e7b3616ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m load_dotenv() \n\u001b[0;32m      5\u001b[0m emb \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings(\n\u001b[0;32m      6\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-3-small\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m vector \u001b[38;5;241m=\u001b[39m emb\u001b[38;5;241m.\u001b[39membed_query(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is a Information technology?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:759\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[1;34m(self, text, **kwargs)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \n\u001b[0;32m    751\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03m    Embedding for the text.\u001b[39;00m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_sync_client_available()\n\u001b[1;32m--> 759\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_documents([text], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:709\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size, **kwargs)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# Unconditionally call _get_len_safe_embeddings to handle length safety.\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;66;03m# This could be optimized to avoid double work when all texts are short enough.\u001b[39;00m\n\u001b[0;32m    708\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 709\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_len_safe_embeddings(\n\u001b[0;32m    710\u001b[0m     texts, engine\u001b[38;5;241m=\u001b[39mengine, chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    711\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:576\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size, **kwargs)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Make API call with this batch\u001b[39;00m\n\u001b[0;32m    575\u001b[0m batch_tokens \u001b[38;5;241m=\u001b[39m tokens[i:batch_end]\n\u001b[1;32m--> 576\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mbatch_tokens, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_kwargs)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    578\u001b[0m     response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\embeddings.py:132\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m             embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    127\u001b[0m                 base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m             )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    134\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(params, embedding_create_params\u001b[38;5;241m.\u001b[39mEmbeddingCreateParams),\n\u001b[0;32m    135\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    136\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers,\n\u001b[0;32m    137\u001b[0m         extra_query\u001b[38;5;241m=\u001b[39mextra_query,\n\u001b[0;32m    138\u001b[0m         extra_body\u001b[38;5;241m=\u001b[39mextra_body,\n\u001b[0;32m    139\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    140\u001b[0m         post_parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[0;32m    141\u001b[0m     ),\n\u001b[0;32m    142\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mCreateEmbeddingResponse,\n\u001b[0;32m    143\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1258\u001b[0m     )\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1044\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1046\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "emb = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "vector = emb.embed_query(\"What is a Information technology?\")\n",
    "#print(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd5c638d-003d-4988-ad88-5a7ed634edf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "emb = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "vector = emb.embed_query(\"What is a Information technology?\")\n",
    "print(len(vector))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477e573-72b2-4649-a1f5-b672e51cf322",
   "metadata": {},
   "source": [
    "### What is a Vector Database?\n",
    "\n",
    "A vector database stores embeddings (vectors) and allows fast similarity search.\n",
    "\n",
    "Situations where this is used:\n",
    "+ Data is unstructured (text, PDFs, images)\n",
    "+ We want meaning-based search, not keywords\n",
    "\n",
    "Text â†’ Embedding â†’ Vector DB â†’ Similarity Search\n",
    "\n",
    "### Why Vector Databases Are Needed\n",
    "\n",
    "1. Normal DBs\n",
    "      1. Store rows & columns\n",
    "      2. Cannot compare meaning\n",
    "2. Vector DBs\n",
    "      1. Store vectors\n",
    "      2. Find closest meaning\n",
    "\n",
    "Some of the applications of Vector Database:\n",
    "+ RAG systems\n",
    "+ Chatbots\n",
    "+ Semantic search\n",
    "+ Recommendation systems\n",
    "\n",
    "Metadata\n",
    "Extra info stored with vectors:\n",
    "+ filename\n",
    "+ category\n",
    "+ page number\n",
    "+ source\n",
    "\n",
    "Used for filtering results\n",
    "\n",
    "### FAISS (Facebook AI Similarity Search)\n",
    "What is FAISS?\n",
    "\n",
    "+ Library by Meta\n",
    "+ Runs locally\n",
    "+ Best for learning & prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "989c5409-c8f5-4f8d-a001-cbf917e69077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "db = FAISS.from_texts(\n",
    "    [\"Silk saree\", \"Cotton saree\"],\n",
    "    OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dbda3d-46ce-4802-89ba-7e97938c1dad",
   "metadata": {},
   "source": [
    "### Chroma\n",
    "What is Chroma?\n",
    "\n",
    "+ Developer-friendly vector DB\n",
    "+ Supports local + persistent storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ffcb122-5863-4c63-8f97-3af680b54951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "db = Chroma.from_texts(\n",
    "    [\"Silk saree\", \"Cotton saree\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c593874-7946-44d1-abe5-9477a7fa7cf8",
   "metadata": {},
   "source": [
    "### Pinecone\n",
    "What is Pinecone?\n",
    "\n",
    "+ Managed cloud vector database\n",
    "+ Production-ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39d2e5f-dc40-45be-8ca8-067f3ae8eb96",
   "metadata": {},
   "source": [
    "### What is Vector Store Indexing? (1-line idea)\n",
    "\n",
    "Vector store indexing is how we store text as vectors along with extra info, so we can search, filter, and retrieve the most relevant content efficiently.\n",
    "\n",
    "Why metadata matters?\n",
    "\n",
    "+ Helps filter results\n",
    "+ Adds context\n",
    "+ Makes retrieval more accurate\n",
    "\n",
    "##### What is filtering?\n",
    "Retrieving vectors only if metadata conditions match.\n",
    "\n",
    "##### Why filtering is important?\n",
    "+ Avoids irrelevant data\n",
    "+ Improves answer quality\n",
    "+ Faster searches"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2288658c-a33d-4ff6-a5fe-958dd460d7cb",
   "metadata": {},
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"filter\": {\"category\": \"saree\"}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653bca48-4a67-4a8d-a030-8ac85da2d8ab",
   "metadata": {},
   "source": [
    "##### What is similarity search?\n",
    "\n",
    "Finding vectors closest in meaning, not exact words.\n",
    "\n",
    "How it works\n",
    "Query â†’ embedding\n",
    "\n",
    "Compare with stored embeddings\n",
    "\n",
    "Return top-k closest vectors"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eccb9736-eebc-4722-bb9b-06cb9c341964",
   "metadata": {},
   "source": [
    "docs = vectorstore.similarity_search(\n",
    "    \"lightweight saree for summer\",\n",
    "    k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e531c-b21d-4165-89f3-21cd27403b85",
   "metadata": {},
   "source": [
    "#### MMR Search (Max Marginal Relevance)\n",
    "Problem with normal similarity search\n",
    "+ Results may be too similar to each other\n",
    "+ Less information coverage\n",
    "\n",
    "##### What MMR does\n",
    "\n",
    "Balances:\n",
    "\n",
    "+ Relevance\n",
    "+ Diversity\n",
    "\n",
    "https://reference.langchain.com/python/langchain_core/vectorstores/#langchain_core.vectorstores.base.VectorStore.max_marginal_relevance_search"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f231f97-6f9f-4efe-ac2b-4b526481ed0c",
   "metadata": {},
   "source": [
    "docs = vectorstore.max_marginal_relevance_search(\n",
    "    query=\"saree types\",\n",
    "    k=5,\n",
    "    fetch_k=10,\n",
    "    lambda_mult=0.5\n",
    ")\n",
    "\n",
    "k = 5 (final results)\n",
    "fetch_k = 10 (initial candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb550046-9ad0-486d-b96d-99718e195dc9",
   "metadata": {},
   "source": [
    "Use MMR when:\n",
    "\n",
    "+ FAQs\n",
    "+ Knowledge bases\n",
    "+ Educational content\n",
    "+ Product recommendations\n",
    "\n",
    "Intuition Behind MMR (Human Thinking)\n",
    "\n",
    "Think like a teacher ðŸ‘©â€ðŸ«:\n",
    "\n",
    "â€œI want good answers, but donâ€™t repeat the same idea again and again.â€\n",
    "\n",
    "MMR thinks:\n",
    "\n",
    "â€œThis result is relevantâ€\n",
    "\n",
    "â€œBut is it too similar to what I already selected?â€\n",
    "\n",
    "+ If yes >>>>> skip\n",
    "+ If no >>>>> include\n",
    "\n",
    "MMR Steps:\n",
    "\n",
    "1. Convert query >>>>> embedding\n",
    "2. Fetch top fetch_k similar docs\n",
    "3. Select the most relevant document first\n",
    "4. For each next selection:\n",
    "     + Penalize docs similar to already selected ones\n",
    "5. Repeat until k docs selected\n",
    "\n",
    "Interview Content\n",
    "+ MMR reduces redundancy in vector search\n",
    "+ MMR balances relevance and diversity\n",
    "+ MMR is ideal for exploratory queries\n",
    "+ Lambda controls relevance vs diversity\n",
    "+ MMR improves RAG context quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fce2750d-e7ec-48e0-a24f-b0cab33d8173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Similarity Search ===\n",
      "\n",
      "1. Returns are accepted within 7 days if unused.\n",
      "\n",
      "2. Silk sarees are best for weddings and festivals.\n",
      "\n",
      "3. Pure silk sarees are traditional and premium.\n",
      "\n",
      "4. Payments: UPI, credit card, debit card, net banking.\n",
      "\n",
      "\n",
      "=== MMR Search ===\n",
      "\n",
      "1. Returns are accepted within 7 days if unused.\n",
      "\n",
      "2. Delivery takes 5 to 7 business days.\n",
      "\n",
      "3. Pure silk sarees are traditional and premium.\n",
      "\n",
      "4. Linen sarees are breathable and modern-looking.\n"
     ]
    }
   ],
   "source": [
    "# pip install -U langchain-core langchain-community faiss-cpu\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings import FakeEmbeddings\n",
    "\n",
    "# 1) Sample docs (intentionally overlapping topics)\n",
    "docs = [\n",
    "    Document(page_content=\"Silk sarees are best for weddings and festivals.\", metadata={\"type\": \"saree\"}),\n",
    "    Document(page_content=\"Pure silk sarees are traditional and premium.\", metadata={\"type\": \"saree\"}),\n",
    "    Document(page_content=\"Cotton sarees are light and great for summer daily wear.\", metadata={\"type\": \"saree\"}),\n",
    "    Document(page_content=\"Linen sarees are breathable and modern-looking.\", metadata={\"type\": \"saree\"}),\n",
    "    Document(page_content=\"Returns are accepted within 7 days if unused.\", metadata={\"type\": \"policy\"}),\n",
    "    Document(page_content=\"Delivery takes 5 to 7 business days.\", metadata={\"type\": \"policy\"}),\n",
    "    Document(page_content=\"Payments: UPI, credit card, debit card, net banking.\", metadata={\"type\": \"payment\"}),\n",
    "]\n",
    "\n",
    "# 2) Build vector store using FakeEmbeddings (no network, no key)\n",
    "emb = FakeEmbeddings(size=1536)\n",
    "vs = FAISS.from_documents(docs, emb)\n",
    "\n",
    "query = \"Tell me about sarees\"\n",
    "\n",
    "# 3) Regular similarity search (often repetitive)\n",
    "sim = vs.similarity_search(query, k=4)\n",
    "\n",
    "print(\"=== Similarity Search ===\")\n",
    "for i, d in enumerate(sim, 1):\n",
    "    print(f\"\\n{i}. {d.page_content}\")\n",
    "\n",
    "# 4) MMR search (relevant + diverse)\n",
    "mmr = vs.max_marginal_relevance_search(\n",
    "    query=query,\n",
    "    k=4,\n",
    "    fetch_k=10,\n",
    "    lambda_mult=0.5\n",
    ")\n",
    "\n",
    "print(\"\\n\\n=== MMR Search ===\")\n",
    "for i, d in enumerate(mmr, 1):\n",
    "    print(f\"\\n{i}. {d.page_content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa3305-87a3-40b9-ad95-0e5e950360cf",
   "metadata": {},
   "source": [
    "### What is Chunking? (Core Definition)\n",
    "\n",
    "Chunking is the process of splitting large text into smaller, meaningful pieces (chunks) before converting them into embeddings.\n",
    "\n",
    "##### What happens without chunking?\n",
    "+ Token limit exceeded because LLMs have max token size\n",
    "+ Poor retrieval happens as Embedding mixes unrelated topics\n",
    "+ Wrong answers are displayed because of Irrelevant context retrieved\n",
    "+ Higher cost and Larger input will eventually lead to higher cost\n",
    "\n",
    "A good chunk should:\n",
    "+ Contain one main idea\n",
    "+ Be self-contained\n",
    "+ Not be too small or too large\n",
    "+ Fit within embedding model limits"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d42e35c6-bded-447e-9e7f-1e577c56d1dd",
   "metadata": {},
   "source": [
    "Raw Documents\n",
    "     â†“\n",
    "Chunking\n",
    "     â†“\n",
    "Embeddings\n",
    "     â†“\n",
    "Vector Store\n",
    "     â†“\n",
    "Retriever\n",
    "     â†“\n",
    "LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaefd65-8ade-4687-bf61-bfa6353f9579",
   "metadata": {},
   "source": [
    "#### Chunk Size (Most Important Decision)\n",
    "What is chunk size?\n",
    "\n",
    "Number of tokens or characters per chunk.\n",
    "\n",
    "##### Common chunk sizes\n",
    "Use case\tChunk size\n",
    "+ Short FAQ\t200â€“400\n",
    "+ Blogs / docs\t500â€“800\n",
    "+ PDFs / manuals\t800â€“1000\n",
    "+ Code\t150â€“300\n",
    "\n",
    "##### Chunk Overlap (Why It Exists)\n",
    "What is overlap?\n",
    "\n",
    "Repeating some part of previous chunk in the next chunk.\n",
    "\n",
    "Why overlap is needed\n",
    "\n",
    "+ Prevents sentence cut-off\n",
    "+ Preserves context\n",
    "+ Improves recall\n",
    "\n",
    "1. Chunk 1: tokens 0â€“500\n",
    "2. Chunk 2: tokens 400â€“900\n",
    "3. Overlap = 100 tokens\n",
    "\n",
    "Fixed-Size Chunking (Baseline Strategy)\n",
    "\n",
    "How it works: Split text purely by size.\n",
    "\n",
    "    Document(page_content=\"Silk sarees are best for weddings and festivals.\", metadata={\"type\": \"saree\"}),\n",
    "    Document(page_content=\"for weddings and festivals. Pure silk sarees are traditional and premium.\", metadata={\"type\": \"saree\"}),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4247654b-fb3b-47a3-90f2-fe33774ee915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd97829-0c7d-43e5-ba26-b4c38d5cde20",
   "metadata": {},
   "source": [
    "##### Recursive Chunking (Recommended)\n",
    "How it works\n",
    "\n",
    "Splits text by:\n",
    "\n",
    "Paragraph\n",
    "\n",
    "Sentence\n",
    "\n",
    "Word\n",
    "\n",
    "Character (fallback)\n",
    "\n",
    "This preserves meaning better"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98ba18a8-2d18-4191-aa96-828d7e24f4b9",
   "metadata": {},
   "source": [
    "RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"],\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9218df9b-c2b7-4398-9d16-7df96a91850b",
   "metadata": {},
   "source": [
    "#### Semantic Chunking (Advanced)\n",
    "\n",
    "Split text based on meaning, not size.\n",
    "\n",
    "Following are Techniques\n",
    "\n",
    "+ Headings based split\n",
    "+ Paragraph based split\n",
    "+ Topic change detection\n",
    "+ LLM-assisted splitting\n",
    "\n",
    "Best suited for:\n",
    "+ Legal documents\n",
    "+ Research papers\n",
    "+ Educational content\n",
    "\n",
    "> Slower and costlier\n",
    "\n",
    "#### Chunking with Metadata (Best Practice)\n",
    "\n",
    "Always attach metadata to each chunk.\n",
    "\n",
    "Interview One-Liners\n",
    "\n",
    "+ Chunking controls retrieval quality\n",
    "+ Chunk size affects cost and accuracy\n",
    "+ Overlap preserves context\n",
    "+ Semantic chunking > fixed chunking\n",
    "+ Poor chunking breaks RAG"
   ]
  },
  {
   "cell_type": "raw",
   "id": "678e9534-c621-4239-b321-44f8bf530625",
   "metadata": {},
   "source": [
    "Document(\n",
    "    page_content=chunk,\n",
    "    metadata={\n",
    "        \"source\": \"product_catalog.pdf\",\n",
    "        \"section\": \"delivery_policy\",\n",
    "        \"page\": 12\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1127d7eb-ed8c-497f-a489-d21fa99e5dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Amazon is a premium online brand that sells silk, cotton, and linen sarees.\n",
    "Silk sarees are best suited for weddings and festivals.\n",
    "Cotton sarees are lightweight and ideal for daily wear and summer.\n",
    "Linen sarees are breathable and modern.\n",
    "\n",
    "Delivery usually takes 5 to 7 business days.\n",
    "Returns are accepted within 7 days if the product is unused.\n",
    "Refunds are processed within 3 business days after pickup.\n",
    "\n",
    "Payment methods include UPI, credit cards, debit cards, and net banking.\n",
    "Cash on delivery is available for select locations.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f5c80b2-3dff-4784-98af-c09c211fea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "doc = Document(page_content=text)\n",
    "vectorstore_no_chunk = FAISS.from_documents([doc], embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2344a1ef-ad53-467e-98cb-100296ebdf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amazon is a premium online brand that sells silk, cotton, and linen sarees.\n",
      "Silk sarees are best suited for weddings and festivals.\n",
      "Cotton sarees are lightweight and ideal for daily wear and summer.\n",
      "Linen sarees are breathable and modern.\n",
      "\n",
      "Delivery usually takes 5 to 7 business days.\n",
      "Returns are accepted within 7 days if the product is unused.\n",
      "Refunds are processed within 3 business days after pickup.\n",
      "\n",
      "Payment methods include UPI, credit cards, debit cards, and net banking.\n",
      "Cash on delivery is available for select locations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = vectorstore_no_chunk.similarity_search(\n",
    "    \"What are the delivery timelines?\",\n",
    "    k=1\n",
    ")\n",
    "\n",
    "# Answers without chunking \n",
    "print(results[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "51fdb2e6-481c-42bb-9d99-b92195bc8297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 2\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Amazon is a premium online brand that sells silk, cotton, and linen sarees.\n",
      "Silk sarees are best suited for weddings and festivals.\n",
      "Cotton sarees are lightweight and ideal for daily wear and summer.\n",
      "Linen sarees are breathable and modern.\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Delivery usually takes 5 to 7 business days.\n",
      "Returns are accepted within 7 days if the product is unused.\n",
      "Refunds are processed within 3 business days after pickup.\n",
      "\n",
      "Payment methods include UPI, credit cards, debit cards, and net banking.\n",
      "Cash on delivery is available for select locations.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "print(f\"Total chunks created: {len(chunks)}\")\n",
    "for i, c in enumerate(chunks):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\\n{c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a6b0ffde-b092-437f-ad5e-e0cea7fcd54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "vectorstore_chunked = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "df70de4a-5092-4766-9885-00af24344712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Retrieved Chunk ---\n",
      "Delivery usually takes 5 to 7 business days.\n",
      "Returns are accepted within 7 days if the product is unused.\n",
      "Refunds are processed within 3 business days after pickup.\n",
      "\n",
      "Payment methods include UPI, credit cards, debit cards, and net banking.\n",
      "Cash on delivery is available for select locations.\n",
      "\n",
      "--- Retrieved Chunk ---\n",
      "Amazon is a premium online brand that sells silk, cotton, and linen sarees.\n",
      "Silk sarees are best suited for weddings and festivals.\n",
      "Cotton sarees are lightweight and ideal for daily wear and summer.\n",
      "Linen sarees are breathable and modern.\n"
     ]
    }
   ],
   "source": [
    "results = vectorstore_chunked.similarity_search(\n",
    "    \"What is the delivery time?\",\n",
    "    k=2\n",
    ")\n",
    "\n",
    "for r in results:\n",
    "    print(\"\\n--- Retrieved Chunk ---\")\n",
    "    print(r.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e69fe33-84e7-4354-a59b-c2a07bac47cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Smaller chunks \n",
    "\n",
    "small_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=30\n",
    ")\n",
    "\n",
    "small_chunks = small_splitter.split_text(text)\n",
    "print(len(small_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "553e21bd-de74-4967-93f6-8019127fc08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "large_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "large_chunks = large_splitter.split_text(text)\n",
    "print(len(large_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ad45efce-e706-425a-9eae-2b8e25ea3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_overlap_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "no_overlap_chunks = no_overlap_splitter.split_text(text)\n",
    "\n",
    "# Overlap preserves continuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c06263a9-25d2-4ecd-b686-c1b78461329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    documents.append(\n",
    "        Document(\n",
    "            page_content=chunk,\n",
    "            metadata={\n",
    "                \"source\": \"mycompany_policy\",\n",
    "                \"chunk_id\": i\n",
    "            }\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "16b9cada-f151-4ad8-86b9-07a92b7de2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MMR Chunk ---\n",
      "Amazon is a premium online brand that sells silk, cotton, and linen sarees.\n",
      "Silk sarees are best suited for weddings and festivals.\n",
      "Cotton sarees are lightweight and ideal for daily wear and summer.\n",
      "Linen sarees are breathable and modern.\n",
      "\n",
      "--- MMR Chunk ---\n",
      "Delivery usually takes 5 to 7 business days.\n",
      "Returns are accepted within 7 days if the product is unused.\n",
      "Refunds are processed within 3 business days after pickup.\n",
      "\n",
      "Payment methods include UPI, credit cards, debit cards, and net banking.\n",
      "Cash on delivery is available for select locations.\n"
     ]
    }
   ],
   "source": [
    "results = vectorstore_chunked.max_marginal_relevance_search(\n",
    "    query=\"Tell me about sarees\",\n",
    "    k=3,\n",
    "    fetch_k=6,\n",
    "    lambda_mult=0.5\n",
    ")\n",
    "\n",
    "for r in results:\n",
    "    print(\"\\n--- MMR Chunk ---\")\n",
    "    print(r.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cb8a8c-1039-446a-97e4-3560870750b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
