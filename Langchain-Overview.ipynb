{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9761c6-fb6d-4237-bbd2-6bd0b04acbc8",
   "metadata": {},
   "source": [
    "## Langchain "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5a7c4c-3e85-4535-af58-66f27acd10ef",
   "metadata": {},
   "source": [
    "#####  What is LangChain?\n",
    "\n",
    "LangChain is a framework that helps you build applications using Large Language Models (LLMs) like GPT, Claude, Gemini, etc.\n",
    "\n",
    "##### Why do we need LangChain?\n",
    "\n",
    "LLMs cannot do these things by themselves:\n",
    "\n",
    "+ Remember past messages\n",
    "+ Search your documents\n",
    "+ Connect to databases\n",
    "+ Call APIs\n",
    "+ Use tools\n",
    "+ Run multi-step reasoning\n",
    "+ Build workflows\n",
    "\n",
    "LangChain provides:\n",
    "\n",
    "- Memory >> LLM remembers previous conversation\n",
    "- Retrieval (RAG) >> LLM can fetch data from PDFs, websites, DBs\n",
    "- Agents >> LLM can think, decide, and call tools\n",
    "- Chains >> multi-step pipelines\n",
    "- Embeddings + Vector DB >> store and search knowledge\n",
    "- Tools >> like Python, search, calculators\n",
    "- LangGraph >> build complex LLM workflows\n",
    "- LangSmith >> evaluation and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b87b92-207f-4071-84bd-6ad3cf9de995",
   "metadata": {},
   "source": [
    "### LangChain Ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a01266-0e11-4b37-a69d-43a5929b9755",
   "metadata": {},
   "source": [
    "\n",
    "The LangChain ecosystem is made of 5 main libraries, each with a specific purpose.\n",
    "Understanding these makes the entire framework easy.\n",
    "\n",
    "##### langchain-core:\n",
    "The foundation of the LangChain ecosystem.\n",
    "\n",
    "It contains the following: \n",
    "+ Prompts (ChatPromptTemplate)\n",
    "+ Runnables / Chains (LCEL pipelines)\n",
    "+ Tools framework\n",
    "+ Messages (HumanMessage, AIMessage)\n",
    "+ Output parsers\n",
    "+ Schema definitions\n",
    "\n",
    "##### langchain-community\n",
    "\n",
    "A big library of community-contributed integrations. Also includes the below ones.\n",
    "\n",
    "+ Vector stores (FAISS, Pinecone, Chromaâ€¦)\n",
    "+ Document loaders (PDF, Excel, websites)\n",
    "+ Embedding models\n",
    "+ Tools (search APIs, calculators)\n",
    "+ Older chain utilities\n",
    "\n",
    "##### langchain-openai\n",
    "The OpenAI integration package >>>>  models, embeddings, chat completions. This keeps LangChain modular. It makes easy to switch model providers and also contains the following\n",
    "\n",
    "+ ChatOpenAI\n",
    "+ OpenAIEmbeddings\n",
    "+ OpenAI client wrappers\n",
    "\n",
    "This is bridge between LangChain and OpenAI/GPT models.\n",
    "\n",
    "##### langgraph\n",
    "A workflow engine for building agents and complex multi-step AI systems. This is where agents officially live now (not inside LangChain). It supports:\n",
    "\n",
    "+ ReAct agents\n",
    "+ State machines\n",
    "+ Loops & conditional workflows\n",
    "+ Human-in-the-loop\n",
    "+ Multi-agent systems\n",
    "\n",
    "The brain + control flow for complex AI reasoning.\n",
    "LangChain = functions, LangGraph = workflows.\n",
    "\n",
    "##### langsmith\n",
    "A platform for debugging, evaluating, and monitoring LLM apps. It provides the following\n",
    "\n",
    "+ Traces of every step in a chain/agent\n",
    "+ Dataset evaluation\n",
    "+ Comparison across models\n",
    "+ Prompt debugging\n",
    "+ Performance analytics\n",
    "\n",
    "The observability & monitoring layer for LangChain applications.\n",
    "LangSmith automatically logs chain/agent calls if enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d07f1b-5f8e-48b1-ba09-1565334b5e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51977d8c-7029-4710-a36d-af1cbe0f2a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "316f4cbe-94cb-4352-9f0c-48db35aaf0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c822f6-eb30-43f7-8400-6c77bdb7d4d4",
   "metadata": {},
   "source": [
    "#### Invoke the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0abbe6d2-ab06-4c48-9b70-5dcfa6c66dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework designed to simplify the development of applications that incorporate large language models (LLMs) and various forms of AI, including chatbots, data processing tasks, and other AI-driven solutions. It provides tools and abstractions that help developers build complex applications more easily by combining language models with external APIs, databases, and other data sources.\n",
      "\n",
      "Key features of LangChain include:\n",
      "\n",
      "1. **Modular Components**: LangChain offers modular components such as chains, prompts, and memory, allowing developers to construct applications with a flexible architecture.\n",
      "\n",
      "2. **Prompt Management**: It helps manage prompt engineering, enabling developers to create, store, and use prompts efficiently.\n",
      "\n",
      "3. **Memory Management**: LangChain includes features that allow applications to maintain context over interactions by using memory to store information between exchanges.\n",
      "\n",
      "4. **Integration**: The framework promotes easy integration with various data sources like databases, APIs, and cloud services, allowing language models to access and utilize information dynamically.\n",
      "\n",
      "5. **Use Case Versatility**: LangChain supports multiple applications, including natural language understanding, chatbots, document analysis, and more, catering to a wide range of domains.\n",
      "\n",
      "Overall, LangChain aims to streamline the process of building LLM applications by providing a cohesive framework that developers can leverage to harness the capabilities of language models effectively.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "response = llm.invoke(\"What is LangChain?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abeb75b-ccb2-4a20-9adb-a4ee92323fd0",
   "metadata": {},
   "source": [
    "#### Chain: Combine prompt >> LLM into one workflow\n",
    "\n",
    "A Chain is a sequence of operations connected together to process input and produce output using an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17e50a78-a5f6-4c8a-9f74-c39a43b753d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b65d74a-f575-412b-bf6d-9bd9ee85d961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic AI refers to artificial intelligence systems that can operate autonomously, make decisions, and take actions in the real world based on their understanding and objectives.\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Explain {topic} in one line.\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "chain = prompt | llm \n",
    "\n",
    "print(chain.invoke({\"topic\": \"Agentic AI\"}).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62643dfd-73d2-4eb8-96da-ebca2a728479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java Spring Boot is a framework that simplifies the development of stand-alone, production-ready Spring-based applications by providing built-in configurations and a range of pre-set features.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"topic\": \"Java Springboot\"}).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f2d565d-3a7d-4b69-afcb-91d602116540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataStage ETL (Extract, Transform, Load) is an IBM tool used to integrate, transform, and load data from various sources into target data warehouses or databases.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"topic\": \"Data Stage ETL\"}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47565c56-a7b7-4acd-ae70-291909670cca",
   "metadata": {},
   "source": [
    "#### Tool: External function the LLM can call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31618e02-936c-4b6f-8a97-8488612a44e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool \n",
    "\n",
    "@tool\n",
    "def add_numbers(x: int, y: int) -> int:\n",
    "    \"\"\"Add two integers and return the result.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "result = add_numbers.invoke({\"x\": 5, \"y\": 10})\n",
    "print(result)  # 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d21328-d9b2-4a7d-8721-b4b510f4531b",
   "metadata": {},
   "source": [
    "#### Agent: LLM that decides which tool to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e049895a-f7e3-42f8-98da-6dc61c25a9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.3\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "222bd0a7-dd54-4eaf-8d5e-02d08d7540f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LotusBlue\\AppData\\Local\\Temp\\ipykernel_22584\\3898682904.py:17: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reversed word \"LangChain\" is \"niahCgnaL\".\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# --- Define Tool ---\n",
    "@tool\n",
    "def reverse_text(text: str) -> str:\n",
    "    \"\"\"Reverse the input text.\"\"\"\n",
    "    return text[::-1]\n",
    "\n",
    "tools = [reverse_text]\n",
    "\n",
    "# --- LLM ---\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# --- Create Agent (NO prompt needed) ---\n",
    "agent = create_react_agent(\n",
    "    model=model,        # Correct argument name\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "# --- Run it ---\n",
    "result = agent.invoke({\n",
    "    \"messages\": [\n",
    "        (\"user\", \"Reverse the word LangChain\")\n",
    "    ]\n",
    "})\n",
    "\n",
    "#print(result)\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e057aa4-f2e3-4a86-b918-f94210fad62b",
   "metadata": {},
   "source": [
    "#### Memory: Store and recall previous messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "011d324b-5973-45f8-b097-c4431afc7a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Keerthi! How can I assist you today?\n",
      "Your name is Keerthi. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Prompt (IMPORTANT: include messages placeholder)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "# Memory store\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_memory = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"messages\"\n",
    ")\n",
    "\n",
    "# --- Interaction 1 ---\n",
    "res1 = with_memory.invoke(\n",
    "    {\"input\": \"My name is Keerthi\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc\"}}\n",
    ")\n",
    "print(res1.content)  \n",
    "\n",
    "\n",
    "# --- Interaction 2 ---\n",
    "res2 = with_memory.invoke(\n",
    "    {\"input\": \"What is my name?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc\"}}\n",
    ")\n",
    "print(res2.content)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc0f3f-de4d-4997-851e-9909ae152319",
   "metadata": {},
   "source": [
    "#### Installation and setup \n",
    "\n",
    "pip install langchain-core langchain-community langchain-openai langgraph\n",
    "\n",
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17cdaea1-a1cf-4983-8d2f-ed44f567e013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework designed to simplify the development of applications powered by language models, enabling seamless integration of various components like tools, models, and data.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"Hello, LangChain! Explain yourself in one line.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a012e2-e722-4f92-a768-ceac4d33c844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
