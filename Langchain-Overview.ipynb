{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9761c6-fb6d-4237-bbd2-6bd0b04acbc8",
   "metadata": {},
   "source": [
    "## Langchain "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5a7c4c-3e85-4535-af58-66f27acd10ef",
   "metadata": {},
   "source": [
    "#####  What is LangChain?\n",
    "\n",
    "LangChain is a framework that helps you build applications using Large Language Models (LLMs) like GPT, Claude, Gemini, etc.\n",
    "\n",
    "##### Why do we need LangChain?\n",
    "\n",
    "LLMs cannot do these things by themselves:\n",
    "\n",
    "+ Remember past messages\n",
    "+ Search your documents\n",
    "+ Connect to databases\n",
    "+ Call APIs\n",
    "+ Use tools\n",
    "+ Run multi-step reasoning\n",
    "+ Build workflows\n",
    "\n",
    "LangChain provides:\n",
    "\n",
    "- Memory >> LLM remembers previous conversation\n",
    "- Retrieval (RAG) >> LLM can fetch data from PDFs, websites, DBs\n",
    "- Agents >> LLM can think, decide, and call tools\n",
    "- Chains >> multi-step pipelines\n",
    "- Embeddings + Vector DB >> store and search knowledge\n",
    "- Tools >> like Python, search, calculators\n",
    "- LangGraph >> build complex LLM workflows\n",
    "- LangSmith >> evaluation and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b87b92-207f-4071-84bd-6ad3cf9de995",
   "metadata": {},
   "source": [
    "### LangChain Ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a01266-0e11-4b37-a69d-43a5929b9755",
   "metadata": {},
   "source": [
    "\n",
    "The LangChain ecosystem is made of 5 main libraries, each with a specific purpose.\n",
    "Understanding these makes the entire framework easy.\n",
    "\n",
    "##### langchain-core:\n",
    "The foundation of the LangChain ecosystem.\n",
    "\n",
    "It contains the following: \n",
    "+ Prompts (ChatPromptTemplate)\n",
    "+ Runnables / Chains (LCEL pipelines)\n",
    "+ Tools framework\n",
    "+ Messages (HumanMessage, AIMessage)\n",
    "+ Output parsers\n",
    "+ Schema definitions\n",
    "\n",
    "##### langchain-community\n",
    "\n",
    "A big library of community-contributed integrations. Also includes the below ones.\n",
    "\n",
    "+ Vector stores (FAISS, Pinecone, Chromaâ€¦)\n",
    "+ Document loaders (PDF, Excel, websites)\n",
    "+ Embedding models\n",
    "+ Tools (search APIs, calculators)\n",
    "+ Older chain utilities\n",
    "\n",
    "##### langchain-openai\n",
    "The OpenAI integration package >>>>  models, embeddings, chat completions. This keeps LangChain modular. It makes easy to switch model providers and also contains the following\n",
    "\n",
    "+ ChatOpenAI\n",
    "+ OpenAIEmbeddings\n",
    "+ OpenAI client wrappers\n",
    "\n",
    "This is bridge between LangChain and OpenAI/GPT models.\n",
    "\n",
    "##### langgraph\n",
    "A workflow engine for building agents and complex multi-step AI systems. This is where agents officially live now (not inside LangChain). It supports:\n",
    "\n",
    "+ ReAct agents\n",
    "+ State machines\n",
    "+ Loops & conditional workflows\n",
    "+ Human-in-the-loop\n",
    "+ Multi-agent systems\n",
    "\n",
    "The brain + control flow for complex AI reasoning.\n",
    "LangChain = functions, LangGraph = workflows.\n",
    "\n",
    "#### langsmith\n",
    "A platform for debugging, evaluating, and monitoring LLM apps. It provides the following\n",
    "\n",
    "+ Traces of every step in a chain/agent\n",
    "+ Dataset evaluation\n",
    "+ Comparison across models\n",
    "+ Prompt debugging\n",
    "+ Performance analytics\n",
    "\n",
    "The observability & monitoring layer for LangChain applications.\n",
    "LangSmith automatically logs chain/agent calls if enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d07f1b-5f8e-48b1-ba09-1565334b5e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51977d8c-7029-4710-a36d-af1cbe0f2a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316f4cbe-94cb-4352-9f0c-48db35aaf0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c822f6-eb30-43f7-8400-6c77bdb7d4d4",
   "metadata": {},
   "source": [
    "#### Invoke the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0abbe6d2-ab06-4c48-9b70-5dcfa6c66dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework designed for developing applications that use large language models (LLMs). It provides a structured approach to building applications that make use of the capabilities of LLMs, enabling developers to create more sophisticated and feature-rich applications. Launched in 2022, LangChain offers a variety of components and tools that help facilitate tasks such as:\n",
      "\n",
      "1. **Chains**: Sequences of calls to LLMs or other processing functions, allowing for complex workflows to be built.\n",
      "\n",
      "2. **Agents**: A mechanism that enables LLMs to interact with their environment, accept user input, and make decisions based on that input.\n",
      "\n",
      "3. **Data Augmented Generation**: Integrating external data sources into the LLM's responses to improve relevancy and accuracy.\n",
      "\n",
      "4. **Memory**: Options for maintaining context and state in conversational AI applications, allowing models to remember past interactions.\n",
      "\n",
      "5. **Integrations**: Compatibility with various data sources, APIs, and tools to build comprehensive applications.\n",
      "\n",
      "LangChain is particularly useful for use cases involving chatbots, conversational agents, document analysis, and question-answering systems, among others. It simplifies the process of leveraging the power of LLMs, making it accessible for developers looking to build intelligent applications without getting bogged down in the complexities of machine learning.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "response = llm.invoke(\"What is LangChain?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abeb75b-ccb2-4a20-9adb-a4ee92323fd0",
   "metadata": {},
   "source": [
    "#### Chain: Combine prompt >> LLM into one workflow\n",
    "\n",
    "A Chain is a sequence of operations connected together to process input and produce output using an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17e50a78-a5f6-4c8a-9f74-c39a43b753d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b65d74a-f575-412b-bf6d-9bd9ee85d961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic AI refers to artificial intelligence systems that can make autonomous decisions and take actions independently to achieve specific goals.\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Explain {topic} in one line.\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "print(chain.invoke({\"topic\": \"Agentic AI\"}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47565c56-a7b7-4acd-ae70-291909670cca",
   "metadata": {},
   "source": [
    "#### Tool: External function the LLM can call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31618e02-936c-4b6f-8a97-8488612a44e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool \n",
    "\n",
    "@tool\n",
    "def add_numbers(x: int, y: int) -> int:\n",
    "    \"\"\"Add two integers and return the result.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "result = add_numbers.invoke({\"x\": 5, \"y\": 10})\n",
    "print(result)  # 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d21328-d9b2-4a7d-8721-b4b510f4531b",
   "metadata": {},
   "source": [
    "#### Agent: LLM that decides which tool to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e049895a-f7e3-42f8-98da-6dc61c25a9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.3\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "222bd0a7-dd54-4eaf-8d5e-02d08d7540f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LotusBlue\\AppData\\Local\\Temp\\ipykernel_24772\\89202948.py:17: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reversed word \"LangChain\" is \"niahCgnaL\".\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# --- Define Tool ---\n",
    "@tool\n",
    "def reverse_text(text: str) -> str:\n",
    "    \"\"\"Reverse the input text.\"\"\"\n",
    "    return text[::-1]\n",
    "\n",
    "tools = [reverse_text]\n",
    "\n",
    "# --- LLM ---\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# --- Create Agent (NO prompt needed) ---\n",
    "agent = create_react_agent(\n",
    "    model=model,        # Correct argument name\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "# --- Run it ---\n",
    "result = agent.invoke({\n",
    "    \"messages\": [\n",
    "        (\"user\", \"Reverse the word LangChain\")\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(result)\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e057aa4-f2e3-4a86-b918-f94210fad62b",
   "metadata": {},
   "source": [
    "#### Memory: Store and recall previous messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "011d324b-5973-45f8-b097-c4431afc7a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hi Keerthi! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 23, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_11f3029f6b', 'id': 'chatcmpl-Cl2wdfSVKLd2hHFCwoeZktvvM6pMb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b05cb-5203-7132-9b79-552cd85c68f2-0' usage_metadata={'input_tokens': 23, 'output_tokens': 12, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content=\"I'm sorry, but I don't know your name. I can't access personal information unless you provide it. How can I assist you today?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 22, 'total_tokens': 49, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_11f3029f6b', 'id': 'chatcmpl-Cl2weUku4XPKP371IcsqJ4BuakXKW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b05cb-58c0-7571-a8c1-1552f5d4d28a-0' usage_metadata={'input_tokens': 22, 'output_tokens': 27, 'total_tokens': 49, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "# Store memory for each session\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Wrap chain with memory\n",
    "with_memory = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"messages\"\n",
    ")\n",
    "\n",
    "# Interactions\n",
    "print(with_memory.invoke(\n",
    "    {\"input\": \"My name is Keerthi\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc\"}}\n",
    "))\n",
    "\n",
    "print(with_memory.invoke(\n",
    "    {\"input\": \"What is my name?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc\"}}\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa63f734-066b-4ebd-bd31-f9bf69a818f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
