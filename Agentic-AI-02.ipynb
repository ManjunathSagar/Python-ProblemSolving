{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20e6728-50b4-4942-8f0a-1aef68f30f9c",
   "metadata": {},
   "source": [
    "# Interview Notes: LangChain Agent Types for GenAI Roles\n",
    "\n",
    "## Overview of Agents\n",
    "Agents are autonomous systems that use LLMs to determine which actions to take and in what order. They maintain a reasoning loop: observe → think → act → repeat until task completion.\n",
    "\n",
    "**Core Components:**\n",
    "- **Agent:** The decision-making LLM that chooses actions\n",
    "- **Tools:** Functions the agent can call (APIs, databases, search engines)\n",
    "- **AgentExecutor:** Orchestrates the agent-tool interaction loop\n",
    "- **Memory:** Stores conversation history and context\n",
    "\n",
    "---\n",
    "\n",
    "## 1. ZeroShotAgent\n",
    "\n",
    "### What It Is\n",
    "A versatile agent that selects tools based on their descriptions alone, without examples. It dynamically decides which tool to use for each step based on the current task.\n",
    "\n",
    "### Key Characteristics\n",
    "- Uses the **ReAct (Reasoning + Acting)** framework\n",
    "- Works with any tool, as long as it has a clear description\n",
    "- No fine-tuning or few-shot examples required\n",
    "- Single-turn action selection per iteration\n",
    "\n",
    "### Prompt Structure\n",
    "```\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tool_descriptions}\n",
    "\n",
    "Use this format:\n",
    "Question: the input question\n",
    "Thought: reasoning about what to do\n",
    "Action: the tool to use\n",
    "Action Input: the input to the tool\n",
    "Observation: the result from the tool\n",
    "... (repeat Thought/Action/Observation as needed)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final response\n",
    "```\n",
    "\n",
    "### Use Cases\n",
    "- Quick prototyping with new tools\n",
    "- Tasks requiring flexible tool selection\n",
    "- General-purpose question answering with tools\n",
    "\n",
    "### Interview Tips\n",
    "- Explain the ReAct framework: interleaving reasoning and actions\n",
    "- Mention limitations: can struggle with complex multi-step reasoning\n",
    "- Discuss when to use vs. other agent types\n",
    "\n",
    "---\n",
    "\n",
    "## 2. ConversationalAgent\n",
    "\n",
    "### What It Is\n",
    "An agent optimized for multi-turn conversations that maintains context across interactions while using tools.\n",
    "\n",
    "### Key Characteristics\n",
    "- Built-in **conversation memory** (ConversationBufferMemory)\n",
    "- Maintains chat history automatically\n",
    "- More natural dialogue flow\n",
    "- Can reference previous exchanges\n",
    "\n",
    "### Prompt Structure\n",
    "```\n",
    "Assistant is a conversational agent designed to help with tasks using tools.\n",
    "\n",
    "TOOLS:\n",
    "{tool_descriptions}\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\n",
    "Current conversation:\n",
    "Human: {input}\n",
    "{agent_scratchpad}\n",
    "```\n",
    "\n",
    "### Differences from ZeroShotAgent\n",
    "- Explicitly includes chat history in prompts\n",
    "- Better at maintaining context over multiple turns\n",
    "- Ideal for chatbots and interactive applications\n",
    "\n",
    "### Use Cases\n",
    "- Customer service chatbots with tool access\n",
    "- Interactive data analysis assistants\n",
    "- Multi-turn task completion (e.g., booking systems)\n",
    "\n",
    "### Interview Tips\n",
    "- Emphasize memory management strategies (buffer, summary, knowledge graph)\n",
    "- Discuss token limits and conversation pruning\n",
    "- Explain how to handle context window constraints\n",
    "\n",
    "---\n",
    "\n",
    "## 3. StructuredChatAgent\n",
    "\n",
    "### What It Is\n",
    "An agent that can handle **complex tool inputs** requiring structured data (JSON objects, nested parameters).\n",
    "\n",
    "### Key Characteristics\n",
    "- Supports multi-parameter tools\n",
    "- Uses JSON for action inputs\n",
    "- Better handling of complex tool schemas\n",
    "- Can pass dictionaries, lists, nested structures\n",
    "\n",
    "### Example Tool Input\n",
    "```json\n",
    "{\n",
    "  \"action\": \"database_query\",\n",
    "  \"action_input\": {\n",
    "    \"query\": \"SELECT * FROM users WHERE age > 25\",\n",
    "    \"database\": \"production\",\n",
    "    \"timeout\": 30,\n",
    "    \"return_format\": \"json\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### When to Use\n",
    "- Tools requiring multiple parameters\n",
    "- APIs with complex request structures\n",
    "- Database queries with multiple filters\n",
    "- Tools needing nested JSON inputs\n",
    "\n",
    "### Advantages Over Basic Agents\n",
    "- More expressive tool calls\n",
    "- Reduces parsing errors with structured inputs\n",
    "- Better for enterprise integrations\n",
    "\n",
    "### Interview Tips\n",
    "- Contrast with ZeroShotAgent's simple string inputs\n",
    "- Discuss JSON schema validation for tools\n",
    "- Mention error handling for malformed inputs\n",
    "\n",
    "---\n",
    "\n",
    "## 4. ReAct Agent\n",
    "\n",
    "### What It Is\n",
    "The foundational agent implementing the **ReAct (Reasoning + Acting) paradigm** from the DeepMind paper.\n",
    "\n",
    "### Core Concept\n",
    "Combines verbal reasoning traces with actions:\n",
    "1. **Thought:** Internal reasoning step\n",
    "2. **Action:** External action via tool\n",
    "3. **Observation:** Result from action\n",
    "4. Repeat until final answer\n",
    "\n",
    "### ReAct Framework Benefits\n",
    "- **Interpretability:** Reasoning is visible\n",
    "- **Debuggability:** Can trace decision path\n",
    "- **Error recovery:** Can self-correct based on observations\n",
    "- **Synergy:** Reasoning improves actions, actions ground reasoning\n",
    "\n",
    "### Example Trace\n",
    "```\n",
    "Question: What's the weather in Paris and should I bring an umbrella?\n",
    "\n",
    "Thought: I need current weather data for Paris\n",
    "Action: weather_api\n",
    "Action Input: Paris, France\n",
    "Observation: Temperature 18°C, rain expected this afternoon\n",
    "\n",
    "Thought: Rain is forecasted, so an umbrella would be useful\n",
    "Final Answer: The weather in Paris is 18°C with rain expected this afternoon. Yes, you should bring an umbrella.\n",
    "```\n",
    "\n",
    "### Interview Tips\n",
    "- Cite the original ReAct paper (Yao et al., 2022)\n",
    "- Explain how it differs from pure chain-of-thought reasoning\n",
    "- Discuss limitations: verbose prompts, higher token usage\n",
    "\n",
    "---\n",
    "\n",
    "## 5. OpenAI Tools Agent (Function Calling Agent)\n",
    "\n",
    "### What It Is\n",
    "A modern agent leveraging **OpenAI's native function calling** API (also supported by other providers like Anthropic).\n",
    "\n",
    "### Key Characteristics\n",
    "- Uses model's built-in function calling capabilities\n",
    "- More reliable tool selection\n",
    "- Structured outputs guaranteed\n",
    "- Lower latency than prompt-based agents\n",
    "- Native support in GPT-3.5-turbo, GPT-4, Claude 3+\n",
    "\n",
    "### How It Works\n",
    "```python\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather for a location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\"type\": \"string\"},\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "### Advantages\n",
    "- **Reliability:** Model explicitly trained for function calling\n",
    "- **Structured outputs:** JSON schema validation\n",
    "- **Parallel tool calls:** Can invoke multiple tools simultaneously\n",
    "- **Lower prompt tokens:** No verbose ReAct prompting needed\n",
    "\n",
    "### Use Cases\n",
    "- Production systems requiring reliability\n",
    "- Applications with strict output formatting\n",
    "- Multi-tool orchestration\n",
    "- Real-time applications (lower latency)\n",
    "\n",
    "### Interview Tips\n",
    "- Explain function calling vs. prompt-based tool use\n",
    "- Discuss parallel function calling for efficiency\n",
    "- Mention model support (OpenAI, Anthropic, Google, etc.)\n",
    "- Compare prompt injection resistance vs. traditional agents\n",
    "\n",
    "---\n",
    "\n",
    "## Comparison Table\n",
    "\n",
    "| Agent Type | Best For | Tool Input | Memory | Complexity |\n",
    "|------------|----------|------------|---------|------------|\n",
    "| ZeroShotAgent | Quick prototyping, simple tools | String | Optional | Low |\n",
    "| ConversationalAgent | Multi-turn chats | String | Built-in | Medium |\n",
    "| StructuredChatAgent | Complex API calls | JSON | Optional | Medium |\n",
    "| ReAct Agent | Transparent reasoning | String | Optional | Medium |\n",
    "| OpenAI Tools Agent | Production reliability | JSON Schema | Optional | Low-Medium |\n",
    "\n",
    "---\n",
    "\n",
    "## Advanced Interview Topics\n",
    "\n",
    "### Agent Execution Strategies\n",
    "- **Max iterations:** Prevent infinite loops\n",
    "- **Early stopping:** Handle tool failures\n",
    "- **Timeout handling:** Manage long-running tools\n",
    "\n",
    "### Error Handling Patterns\n",
    "```python\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    max_iterations=5,\n",
    "    handle_parsing_errors=True,\n",
    "    return_intermediate_steps=True\n",
    ")\n",
    "```\n",
    "\n",
    "### Custom Agent Creation\n",
    "- Extending base Agent class\n",
    "- Custom prompt templates\n",
    "- Tool result parsing\n",
    "- Output formatting\n",
    "\n",
    "### Production Considerations\n",
    "- **Token optimization:** Minimize prompt size\n",
    "- **Caching:** Reduce repeated LLM calls\n",
    "- **Monitoring:** Track tool usage and failures\n",
    "- **Fallback strategies:** Handle model unavailability\n",
    "- **Cost management:** Balance capability vs. expense\n",
    "\n",
    "### Multi-Agent Systems\n",
    "- Agent collaboration patterns\n",
    "- Hierarchical agent structures\n",
    "- Specialized vs. generalist agents\n",
    "- Communication protocols between agents\n",
    "\n",
    "---\n",
    "\n",
    "## Common Interview Questions\n",
    "\n",
    "**Q: When would you choose StructuredChatAgent over OpenAI Tools Agent?**\n",
    "A: StructuredChatAgent when using models without native function calling or when you need more control over the prompting strategy. OpenAI Tools Agent for production reliability with supported models.\n",
    "\n",
    "**Q: How do you prevent agent hallucinations with tools?**\n",
    "A: Clear tool descriptions, output validation, structured outputs, setting max iterations, and using models with function calling support.\n",
    "\n",
    "**Q: How would you optimize agent performance in production?**\n",
    "A: Caching tool results, minimizing prompt tokens, using parallel tool calls, implementing timeouts, monitoring tool reliability, and choosing appropriate models for cost-performance trade-offs.\n",
    "\n",
    "**Q: What's the difference between ReAct and Chain-of-Thought?**\n",
    "A: Chain-of-Thought is pure reasoning without actions. ReAct interleaves reasoning with real-world actions via tools, allowing the agent to ground its thinking in observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe76581-f338-4fdd-a873-e117d1d0d6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 multiplied by 8 is 56.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ZeroShotAgent (LangChain 1.x equivalent)\n",
    "---------------------------------------\n",
    "• In \"classic\" LangChain, ZeroShotAgent was commonly used via initialize_agent(..., AgentType.ZERO_SHOT_*).\n",
    "• In LangChain 1.x, the recommended approach is create_agent(...), which runs the core loop:\n",
    "  model -> (optional tool calls) -> final answer.\n",
    "• Use this for single-turn tasks where you want the LLM to pick tools based on tool docstrings.\n",
    "\n",
    "ZeroShotAgent\n",
    "-------------\n",
    "• Uses LLM reasoning only (no memory of prior conversation)\n",
    "• Chooses tools based on tool descriptions\n",
    "• Best for single-turn reasoning + tool usage\n",
    "• No structured output enforcement\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers and return the product.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[multiply],\n",
    "    system_prompt=\"You are a helpful assistant. Use tools when needed.\"\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is 7 multiplied by 8?\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e976578-8f9f-4728-b390-651143f03de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The weather in Bengaluru is sunny.\n",
      "Assistant: The weather in Mysuru is also sunny.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ConversationalAgent (LangChain 1.x equivalent)\n",
    "----------------------------------------------\n",
    "• \"ConversationalAgent\" in classic LangChain focused on multi-turn chat with memory.\n",
    "• In LangChain 1.x, conversation history is carried in the agent state via the 'messages' list.\n",
    "• You keep/append messages between turns and pass them back in on the next invoke().\n",
    "• Optional: add SummarizationMiddleware when message history grows large (not shown here).\n",
    "\n",
    "ConversationalAgent\n",
    "-------------------\n",
    "• Designed for multi-turn chat\n",
    "• Maintains conversation context\n",
    "• Still uses tools when required\n",
    "• Ideal for chatbots + assistants\n",
    "\"\"\"\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Return a simple weather string for a given city.\"\"\"\n",
    "    return f\"Weather in {city}: Sunny\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"You are a conversational assistant. Keep context from prior messages.\"\n",
    ")\n",
    "\n",
    "# --- Turn 1\n",
    "state = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is the weather in Bengaluru?\"}\n",
    "    ]\n",
    "}\n",
    "result1 = agent.invoke(state)\n",
    "\n",
    "assistant_msg_1 = result1[\"messages\"][-1]\n",
    "print(\"Assistant:\", assistant_msg_1.content)\n",
    "\n",
    "# --- Turn 2 (carry forward messages)\n",
    "state[\"messages\"].append({\"role\": \"assistant\", \"content\": assistant_msg_1.content})\n",
    "state[\"messages\"].append({\"role\": \"user\", \"content\": \"And what about Mysuru?\"})\n",
    "\n",
    "result2 = agent.invoke(state)\n",
    "print(\"Assistant:\", result2[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "671b5dfb-ea7b-4a10-8449-e621095d257c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured: destination='Delhi' date='2026-02-10' num_passengers=2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "StructuredChatAgent\n",
    "-------------------\n",
    "• Forces structured (JSON-like) responses\n",
    "• Best for APIs, backend systems\n",
    "• Prevents free-text hallucination\n",
    "• Excellent for automation pipelines\n",
    "\n",
    "StructuredChatAgent (LangChain 1.x equivalent)\n",
    "----------------------------------------------\n",
    "• Classic StructuredChatAgent tried to enforce structured / JSON-like outputs.\n",
    "• In LangChain 1.x, the built-in way is response_format=ToolStrategy(Schema) or ProviderStrategy(Schema).\n",
    "• ToolStrategy works with tool-calling models and returns structured data in result[\"structured_response\"].\n",
    "\"\"\"\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class TicketRequest(BaseModel):\n",
    "    destination: str\n",
    "    date: str\n",
    "    num_passengers: int\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],  # tools optional; structured output can be used even without tools\n",
    "    response_format=ToolStrategy(TicketRequest),\n",
    "    system_prompt=\"Extract the booking request as structured data.\"\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Book 2 tickets to Delhi for 2026-02-10\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Structured:\", result[\"structured_response\"])   # -> TicketRequest(...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7853e188-39ea-4d55-b080-cd4f5e0aed79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ReAct framework in agentic AI refers to a method that combines reasoning and acting, enabling AI systems to make decisions based on both logical reasoning and real-time interactions with their environment. This approach enhances the adaptability and effectiveness of AI agents in dynamic situations.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ReAct Agent\n",
    "-----------\n",
    "• Explicit Reasoning → Action → Observation loop\n",
    "• Thinks step-by-step before using tools\n",
    "• Most important agent conceptually\n",
    "• Foundation of modern Agentic AI\n",
    "\n",
    "ReAct Agent (LangChain 1.x equivalent)\n",
    "--------------------------------------\n",
    "• ReAct = Reasoning + Acting via tools (loop until no more tool calls).\n",
    "• In LangChain 1.x, create_agent(...) is the standard agent loop that supports tool calling naturally.\n",
    "• If you stream, you can see intermediate steps/messages (tool calls, tool results, etc.).\n",
    "\"\"\"\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search the web (mock). Return quick 'results' for a query.\"\"\"\n",
    "    return f\"[MOCK] Top results for: {query}\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[search],\n",
    "    system_prompt=\"You are a research assistant. Use the search tool when you need facts.\"\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Find what ReAct means in agentic AI and summarize in 2 lines.\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1082dbd-8df5-4109-84e6-e769bef86444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of 15 and 27 is 42.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "OpenAI Tools Agent\n",
    "------------------\n",
    "• Uses OpenAI function calling / tools API\n",
    "• Most reliable & production-ready\n",
    "• Clean tool invocation (no text parsing)\n",
    "• Recommended agent going forward\n",
    "\n",
    "OpenAI Tools Agent (LangChain 1.x equivalent)\n",
    "---------------------------------------------\n",
    "• In classic LangChain, \"OpenAI Tools Agent\" referred to OpenAI function/tool calling based agents.\n",
    "• In LangChain 1.x, create_agent(...) + a tool-calling model (e.g., ChatOpenAI) gives you that behavior.\n",
    "• This is the most \"modern\" default agent style in v1: clean tool calls, reliable execution loop.\n",
    "\"\"\"\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and return the sum.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[add],\n",
    "    system_prompt=\"Use tools for math instead of guessing.\"\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Add 15 and 27\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466cda87-59bd-4822-bc0c-cb4ca9b79062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
